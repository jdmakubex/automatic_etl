networks:
  etl_net:
    external: true
    name: etl_prod_etl_net

volumes:
  ch_data:
  superset_home:
  kafka_data:
  connect_data:

services:
  # ---------- CLICKHOUSE ----------
  clickhouse:
    image: clickhouse/clickhouse-server:24.3
    container_name: clickhouse
    networks: [etl_net]
    environment:
      - CLICKHOUSE_DB=${CLICKHOUSE_DATABASE:-fgeo_analytics}
      - CLICKHOUSE_USER=default
      - CLICKHOUSE_PASSWORD=
    ports:
      - "8123:8123"     # HTTP
      - "9000:9000"     # Native
    volumes:
      - ch_data:/var/lib/clickhouse
      - ./bootstrap/clickhouse_init.sql:/docker-entrypoint-initdb.d/00_init.sql:ro
    healthcheck:
      test: ["CMD-SHELL", "wget -qO- http://localhost:8123/ping | grep -q 'Ok'"]
      interval: 10s
      timeout: 5s
      retries: 12
    restart: unless-stopped

  # ---------- SUPERSET ----------
  superset:
    build:
      context: .
      dockerfile: ./superset.Dockerfile
    container_name: superset
    profiles: ["bulk","cdc"]
    networks: [etl_net]
    environment:
      - SUPERSET_ENV=production
      - SUPERSET_LOAD_EXAMPLES=no
      - SUPERSET_SECRET_KEY=please_change_me
    volumes:
      - superset_home:/app/superset_home
      - ./superset_bootstrap:/bootstrap:ro
    ports:
      - "8088:8088"
    depends_on:
      clickhouse: { condition: service_healthy }
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:8088/health || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 30
    restart: unless-stopped

  superset-init:
    image: apache/superset:3.1.0
    container_name: superset-init
    profiles: ["bulk","cdc"]
    networks: [etl_net]
    environment:
      - SUPERSET_ADMIN=${SUPERSET_ADMIN:-admin}
      - SUPERSET_PASSWORD=${SUPERSET_PASSWORD:-Admin123!}
    depends_on:
      superset: { condition: service_healthy }
    entrypoint: ["/bin/sh","-lc"]
    command: >
      set -e;
      superset fab create-admin --username "$SUPERSET_ADMIN" --firstname Admin --lastname User
      --email admin@example.com --password "$SUPERSET_PASSWORD" || true;
      superset db upgrade;
      superset init;
      superset import-datasources -p /bootstrap/clickhouse_db.yaml || true;
      echo SUPerset_INIT_OK;
    restart: "no"

  # ---------- KAFKA (Confluent, KRaft 1 nodo combinado) ----------
  kafka:
    image: confluentinc/cp-kafka:8.0.1
    container_name: kafka
    profiles: ["cdc"]
    networks: [etl_net]
    ports:
      - "19092:19092"   # acceso desde host
    environment:
      # ID de clúster para KRaft; puedes generar otro, o usar el de tu .env
      - CLUSTER_ID=${KAFKA_CLUSTER_ID:-MkU3OEVBNTcwNTJENDM2Qk}
      # KRaft combinado (solo para dev/local)
      - KAFKA_NODE_ID=1
      - KAFKA_PROCESS_ROLES=broker,controller
      - KAFKA_CONTROLLER_QUORUM_VOTERS=1@kafka:9093
      - KAFKA_CONTROLLER_LISTENER_NAMES=CONTROLLER
      # Listeners y advertised (interno + host)
      - KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093,PLAINTEXT_HOST://0.0.0.0:19092
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092,PLAINTEXT_HOST://host.docker.internal:19092
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      - KAFKA_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      # Dev (1 broker)
      - KAFKA_AUTO_CREATE_TOPICS_ENABLE=true
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      - KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1
      - KAFKA_TRANSACTION_STATE_LOG_MIN_ISR=1
    volumes:
      - kafka_data:/var/lib/kafka/data
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --bootstrap-server localhost:9092 --list >/dev/null 2>&1"]
      interval: 10s
      timeout: 5s
      retries: 30
    restart: unless-stopped

  # ---------- KAFKA CONNECT con Debezium ----------
  connect:
    image: debezium/connect:2.6
    container_name: connect
    profiles: ["cdc"]
    networks: [etl_net]
    depends_on:
      kafka: { condition: service_healthy }
    environment:
      - BOOTSTRAP_SERVERS=kafka:9092
      - GROUP_ID=1
      - CONFIG_STORAGE_TOPIC=connect_configs
      - OFFSET_STORAGE_TOPIC=connect_offsets
      - STATUS_STORAGE_TOPIC=connect_statuses
      - KEY_CONVERTER=org.apache.kafka.connect.json.JsonConverter
      - VALUE_CONVERTER=org.apache.kafka.connect.json.JsonConverter
      - REST_ADVERTISED_HOST_NAME=connect
      - REST_PORT=8083
    ports:
      - "8083:8083"
    volumes:
      - connect_data:/kafka
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:8083/connectors >/dev/null"]
      interval: 10s
      timeout: 5s
      retries: 60
    restart: unless-stopped

  # ---------- CONFIGURADOR (usa tus scripts) ----------
  configurator:
    image: python:3.11-slim
    container_name: configurator
    profiles: ["bulk","cdc"]
    working_dir: /app
    env_file:
      - .env
    environment:
      - CONNECT_URL=http://connect:8083
      - CLICKHOUSE_URL=http://clickhouse:8123
      - CLICKHOUSE_DATABASE=${CLICKHOUSE_DATABASE:-fgeo_analytics}
      - DB_CONNECTIONS=${DB_CONNECTIONS}
    networks: [etl_net]
    volumes:
      - ./:/app
      - ./superset_bootstrap:/bootstrap:ro
    entrypoint: ["bash","-lc"]
    command: >
      set -euo pipefail;
      python -m pip install --no-cache-dir -q python-dotenv requests clickhouse-connect SQLAlchemy PyMySQL;
      python tools/render_from_env.py
    depends_on:
      clickhouse: { condition: service_healthy }
    restart: unless-stopped

  # ---------- BOOTSTRAP CDC automático (one-shot) ----------
  cdc-bootstrap:
    image: python:3.11-slim
    container_name: cdc-bootstrap
    profiles: ["cdc"]
    working_dir: /app
    env_file:
      - .env
    environment:
      - CONNECT_URL=http://connect:8083
      - CLICKHOUSE_URL=http://clickhouse:8123
      - CLICKHOUSE_DATABASE=${CLICKHOUSE_DATABASE:-fgeo_analytics}
      - DB_CONNECTIONS=${DB_CONNECTIONS}
      - CLICKHOUSE_HTTP_HOST=clickhouse
      - CLICKHOUSE_HTTP_PORT=8123
      - CLICKHOUSE_DATABASE=fgeo_analytics
      - CH_USER=etl
      - CH_PASSWORD=Et1Ingest!
    networks: [etl_net]
    volumes:
      - ./:/app
    depends_on:
      connect: { condition: service_healthy }
      clickhouse: { condition: service_healthy }
    entrypoint:
    - python
    - tools/cdc_bootstrap.py

  cdc:
      image: python:3.12-slim
      working_dir: /app
      volumes:
        - ./:/app:rw
      environment:
        CLICKHOUSE_HTTP_HOST: clickhouse
        CLICKHOUSE_HTTP_PORT: "8123"
        CLICKHOUSE_DATABASE: fgeo_analytics
        CH_USER: etl
        CH_PASSWORD: Et1Ingest!
      depends_on:
        - clickhouse
      entrypoint:
        - python
        - tools/cdc_bootstrap.py


  restart: "no"
