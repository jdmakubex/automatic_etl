# üìã GU√çA DE CONFIGURACI√ìN DEL PIPELINE ETL

## üéØ Resumen
Este proyecto implementa un pipeline ETL completo que replica datos desde MySQL hacia ClickHouse usando Kafka/Debezium, con un dashboard en Apache Superset. **Toda la configuraci√≥n est√° centralizada en el archivo `.env`** para garantizar consistencia y facilitar la replicaci√≥n.

## ‚ö° Inicio R√°pido

### 1. Preparaci√≥n del Entorno
```bash
# Clonar el repositorio
git clone [tu-repositorio]
cd etl_prod

# Verificar que Docker est√° instalado y funcionando
docker --version
docker compose version
```

### 2. Configuraci√≥n
```bash
# El archivo .env ya est√° configurado con valores por defecto
# SOLO MODIFICA estas variables seg√∫n tu entorno:

# En .env, cambiar estas l√≠neas:
MYSQL_HOST=172.21.61.53          # ‚Üê Tu servidor MySQL
MYSQL_USER=juan.marcos           # ‚Üê Tu usuario MySQL  
MYSQL_PASSWORD=123456            # ‚Üê Tu contrase√±a MySQL
MYSQL_DATABASE=archivos          # ‚Üê Tu base de datos MySQL
```

### 3. Validaci√≥n y Ejecuci√≥n
```bash
# Validar configuraci√≥n
python3 tools/validate_config.py

# Iniciar pipeline completo (autom√°tico)
./tools/start_pipeline.sh --clean

# O de forma manual:
docker compose down && docker compose up -d
```

### 4. Verificaci√≥n
```bash
# Verificar estado
docker compose ps
docker compose exec etl-tools python3 tools/pipeline_status.py

# Ver logs
docker compose logs -f
```

## üîß Configuraci√≥n Avanzada

### Variables Cr√≠ticas en `.env`

#### MySQL (Base de Datos Origen)
```bash
MYSQL_HOST=172.21.61.53                    # IP del servidor MySQL
MYSQL_PORT=3306                            # Puerto MySQL
MYSQL_USER=juan.marcos                     # Usuario con permisos de lectura
MYSQL_PASSWORD=123456                      # Contrase√±a del usuario
MYSQL_DATABASE=archivos                    # Base de datos a replicar
```

#### ClickHouse (Base de Datos Destino)
```bash
CLICKHOUSE_HOST=clickhouse                 # Siempre "clickhouse" (servicio Docker)
CLICKHOUSE_HTTP_PORT=8123                  # Puerto HTTP (default 8123)
CLICKHOUSE_DATABASE=fgeo_analytics         # BD destino en ClickHouse
CH_USER=etl                               # Usuario ETL
CH_PASSWORD=Et1Ingest!                    # Contrase√±a usuario ETL
```

#### Kafka/Debezium (Streaming)
```bash
KAFKA_BROKERS=kafka:9092                  # Siempre "kafka:9092" (interno)
CONNECT_URL=http://connect:8083           # URL de Kafka Connect
DBZ_SERVER_NAME_PREFIX=dbserver           # Prefijo para t√≥picos
DBZ_SNAPSHOT_MODE=initial                 # Modo snapshot inicial
```

Nota importante sobre credenciales Debezium:
- Las variables DBZ_DATABASE_HOSTNAME/PORT/USER/PASSWORD est√°n DEPRECADAS y se ignoran.
- Las credenciales y bases de datos de origen se toman exclusivamente de DB_CONNECTIONS (JSON en .env).
- Mant√©n una sola fuente de verdad para evitar inconsistencias.

#### Superset (Dashboard)
```bash
SUPERSET_URL=http://superset:8088         # URL de Superset
SUPERSET_ADMIN=admin                      # Usuario administrador
SUPERSET_PASSWORD=Admin123!               # Contrase√±a admin
```

## üöÄ Servicios Disponibles

Despu√©s del despliegue exitoso:

| Servicio | URL | Credenciales |
|----------|-----|--------------|
| **Superset** | http://localhost:8088 | admin / Admin123! |
| **ClickHouse** | http://localhost:8123 | etl / Et1Ingest! |
| **Kafka Connect** | http://localhost:8083 | - |

## üìä Arquitectura

```
MySQL (Origen) 
    ‚Üì CDC
Debezium/Kafka 
    ‚Üì Stream
ClickHouse (Destino)
    ‚Üì Analytics
Superset (Dashboard)
```

## üîç Verificaci√≥n del Pipeline

### Comandos de Diagn√≥stico
```bash
# Estado general
docker compose ps

# Verificar bases de datos
docker compose exec clickhouse clickhouse-client --query "SHOW DATABASES"
docker compose exec clickhouse clickhouse-client --query "SHOW TABLES FROM fgeo_analytics"

# Verificar conectores
docker compose exec connect curl -s http://connect:8083/connectors

# Verificar t√≥picos Kafka
docker compose exec kafka kafka-topics --bootstrap-server kafka:9092 --list

# Pipeline status completo
docker compose exec etl-tools python3 tools/pipeline_status.py
```

### Logs de Servicios
```bash
# Todos los servicios
docker compose logs -f

# Servicio espec√≠fico
docker compose logs -f clickhouse
docker compose logs -f connect
docker compose logs -f superset
```

## üõ†Ô∏è Troubleshooting

### Problema: Servicios no inician
```bash
# Limpiar y reiniciar
docker compose down -v
docker system prune -f
./tools/start_pipeline.sh --clean
```

### Problema: Conectores fallan
```bash
# Verificar conectividad MySQL
docker compose exec etl-tools python3 -c "
import pymysql
conn = pymysql.connect(host='172.21.61.53', port=3306, user='juan.marcos', password='123456', db='archivos')
print('‚úÖ MySQL conectado')
conn.close()
"

# Reaplicar conectores
docker compose exec etl-tools python3 tools/apply_connectors_auto.py
```

### Problema: No hay datos en ClickHouse
```bash
# Verificar que Debezium est√° replicando
docker compose exec kafka kafka-topics --bootstrap-server kafka:9092 --list | grep dbserver

# Verificar mensajes en t√≥picos
docker compose exec kafka kafka-console-consumer --bootstrap-server kafka:9092 --topic dbserver_default.archivos.archivos --from-beginning --max-messages 5
```

## ÔøΩ Nota sobre CDC Bootstrap y permisos

Para evitar errores de permisos durante el paso de CDC (instalaci√≥n de dependencias y generaci√≥n/aplicaci√≥n de artefactos):

- El servicio `cdc-bootstrap` corre como `root` y define `HOME=/root` para que `pip` pueda instalar paquetes en contenedores base slim.
- Se monta el directorio `./generated` en `/app/generated` para garantizar escritura de artefactos (conectores y SQLs) desde el bootstrap.
- Variables relevantes en `docker-compose.yml` dentro de `cdc-bootstrap`:
    - `user: "0:0"`
    - `environment: [HOME=/root, PIP_ROOT_USER_ACTION=ignore]`
    - `volumes: [./generated:/app/generated]`

Con esto, el paso 5/5 (Bootstrap CDC) se ejecuta de forma idempotente y sin errores de permisos.

## ÔøΩüìÅ Estructura del Proyecto

```
etl_prod/
‚îú‚îÄ‚îÄ .env                     # ‚Üê CONFIGURACI√ìN PRINCIPAL
‚îú‚îÄ‚îÄ docker-compose.yml      # Definici√≥n de servicios
‚îú‚îÄ‚îÄ tools/                  # Scripts de automatizaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ start_pipeline.sh   # ‚Üê Script principal de inicio
‚îÇ   ‚îú‚îÄ‚îÄ validate_config.py  # Validador de configuraci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ gen_pipeline.py     # Generador de configuraciones
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ generated/              # Configuraciones generadas
‚îî‚îÄ‚îÄ logs/                   # Logs del sistema
```

## üîí Variables de Seguridad

**IMPORTANTE**: Para producci√≥n, cambiar estas variables:

```bash
# En .env
SUPERSET_SECRET_KEY=TuClaveSecretaSuperSegura123456789
CLICKHOUSE_ETL_PASSWORD=TuPasswordSeguroClickHouse123
SUPERSET_PASSWORD=TuPasswordSeguroSuperset123
```

## ü§ù Para el Equipo

### Al clonar el proyecto:
1. Copia el archivo `.env` y ajusta **solo** las variables MySQL seg√∫n tu entorno
2. Ejecuta `python3 tools/validate_config.py` para verificar configuraci√≥n
3. Ejecuta `./tools/start_pipeline.sh --clean` para desplegar
4. Verifica con `docker compose ps` que todos los servicios est√°n healthy

### No modificar directamente:
- `docker-compose.yml` (usa variables de `.env`)
- Scripts en `tools/` (usan configuraci√≥n centralizada)
- Archivos en `generated/` (se regeneran autom√°ticamente)

### Si hay problemas:
1. Ejecutar `docker compose logs -f [servicio]` para ver logs
2. Ejecutar `python3 tools/validate_config.py` para verificar configuraci√≥n
3. Ejecutar `./tools/start_pipeline.sh --clean` para reinicio limpio

## üìû Soporte

Para problemas:
1. Verificar logs: `docker compose logs -f`
2. Validar configuraci√≥n: `python3 tools/validate_config.py`
3. Estado del pipeline: `docker compose exec etl-tools python3 tools/pipeline_status.py`

---
**‚úÖ Con esta configuraci√≥n centralizada, el proyecto deber√≠a funcionar consistentemente en cualquier entorno con m√≠nimos ajustes.**