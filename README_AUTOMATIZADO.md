# ğŸš€ PIPELINE ETL AUTOMÃTICO - MySQL â†’ Kafka â†’ ClickHouse

## ğŸ¯ DESCRIPCIÃ“N

Pipeline ETL completamente automatizado que replica datos desde MySQL hacia ClickHouse usando Kafka/Debezium con **inicializaciÃ³n automÃ¡tica desde cero**.

### âœ¨ CARACTERÃSTICAS PRINCIPALES

- **ğŸ”„ Completamente AutomÃ¡tico**: Un solo comando inicia todo el pipeline
- **ğŸ§¹ Auto-limpieza**: Elimina configuraciones previas para evitar conflictos  
- **ğŸ” Auto-descubrimiento**: Detecta automÃ¡ticamente tablas MySQL
- **ğŸ‘¥ Auto-configuraciÃ³n**: Crea usuarios y permisos necesarios
- **ğŸ—ï¸ Auto-optimizaciÃ³n**: Genera esquemas ClickHouse optimizados
- **ğŸ“Š Monitoreo completo**: Logs detallados de cada paso
- **âœ… ValidaciÃ³n automÃ¡tica**: Verifica flujo completo de datos

## ğŸš€ INICIO RÃPIDO

### Prerequisitos

- Docker y Docker Compose
- Acceso a base de datos MySQL origen
- Puertos 8088, 8123, 8083, 19092 disponibles

### 1. ConfiguraciÃ³n Inicial

```bash
# Clonar el repositorio
git clone <repo-url>
cd etl_prod

# Configurar variables de entorno
cp .env.example .env
# Editar .env con credenciales MySQL
```

### 2. Iniciar Pipeline AutomÃ¡tico

```bash
# Inicio completo automÃ¡tico (RECOMENDADO)
./start_etl_pipeline.sh

# Inicio con limpieza forzada
./start_etl_pipeline.sh --clean

# Inicio manual (solo servicios, sin orquestaciÃ³n)  
./start_etl_pipeline.sh --manual

# Ver ayuda completa
./start_etl_pipeline.sh --help
```

### 3. Verificar Estado

```bash
# Verificar estado del pipeline
python3 tools/pipeline_status.py

# Ver logs detallados
tail -f logs/orchestrator.log
```

## ğŸ—ï¸ ARQUITECTURA

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    MySQL    â”‚â”€â”€â”€â–¶â”‚    Kafka    â”‚â”€â”€â”€â–¶â”‚ ClickHouse  â”‚â”€â”€â”€â–¶â”‚  Superset   â”‚
â”‚   (Origen)  â”‚    â”‚ (Streaming) â”‚    â”‚ (AnalÃ­tica) â”‚    â”‚(Visualiza.) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚ Debezium CDC  â”‚
                   â”‚ (Conectores)  â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Servicios Incluidos

- **ClickHouse**: Base de datos analÃ­tica (puerto 8123)
- **Kafka**: Streaming de datos con KRaft
- **Kafka Connect**: Conectores Debezium para CDC
- **Superset**: VisualizaciÃ³n y dashboards (puerto 8088)
- **Orquestador**: InicializaciÃ³n automÃ¡tica

## ğŸ›ï¸ PROCESO DE AUTOMATIZACIÃ“N

El orquestador ejecuta automÃ¡ticamente estas **6 fases**:

### ğŸ§¹ FASE 1: LIMPIEZA COMPLETA
- Elimina conectores Kafka Connect existentes
- Limpia tÃ³picos de Kafka relacionados
- Borra tablas y datos de ClickHouse
- Remueve archivos de configuraciÃ³n previos

### ğŸ‘¥ FASE 2: CONFIGURACIÃ“N DE USUARIOS  
- Crea usuario MySQL con permisos de replicaciÃ³n
- Configura usuario ClickHouse con permisos de escritura
- Valida conectividad a ambas bases de datos
- Guarda credenciales para uso posterior

### ğŸ” FASE 3: DESCUBRIMIENTO DE ESQUEMAS
- Se conecta a MySQL y detecta todas las tablas
- Analiza estructura de columnas y tipos de datos
- Genera configuraciones de conectores Debezium
- Crea metadatos para creaciÃ³n de esquemas

### ğŸ—ï¸ FASE 4: CREACIÃ“N DE MODELOS
- Genera esquemas ClickHouse optimizados
- Mapea tipos MySQL â†’ ClickHouse automÃ¡ticamente
- Configura engines apropiados (MergeTree, etc.)
- Crea tablas con particionado y ordenamiento Ã³ptimo

### ğŸ”Œ FASE 5: DESPLIEGUE DE CONECTORES
- Aplica conectores Debezium automÃ¡ticamente
- Configura CDC (Change Data Capture)
- Inicia flujo de datos MySQL â†’ Kafka
- Verifica estado de conectores

### âœ… FASE 6: VALIDACIÃ“N COMPLETA
- Confirma tÃ³picos de Kafka con datos
- Verifica datos en ClickHouse
- Valida flujo completo de extremo a extremo
- Genera reporte de estado final

## ğŸ“‹ CONFIGURACIÃ“N

### Variables de Entorno Principales

```bash
# MySQL Origen
MYSQL_HOST=host.docker.internal
MYSQL_PORT=3306
MYSQL_ADMIN_USER=root
MYSQL_ADMIN_PASSWORD=admin
MYSQL_DATABASE=archivos

# ClickHouse Destino  
CLICKHOUSE_DATABASE=fgeo_analytics

# Superset
SUPERSET_ADMIN=admin
SUPERSET_PASSWORD=Admin123!
```

### Archivos de ConfiguraciÃ³n Generados

DespuÃ©s de la inicializaciÃ³n automÃ¡tica:

```
generated/default/
â”œâ”€â”€ mysql_connector_auto.json      # ConfiguraciÃ³n conector MySQL
â”œâ”€â”€ .env_auto                       # Credenciales generadas
â”œâ”€â”€ tables_metadata.json           # Metadatos de tablas
â”œâ”€â”€ clickhouse_validation.json     # Resultados de validaciÃ³n
â””â”€â”€ schemas/
    â”œâ”€â”€ tabla1_clickhouse.sql      # Schema ClickHouse tabla 1
    â”œâ”€â”€ tabla2_clickhouse.sql      # Schema ClickHouse tabla 2
    â””â”€â”€ ...
```

## ğŸ” MONITOREO Y LOGS

### Logs Principales

```bash
logs/
â”œâ”€â”€ orchestrator.log               # Log principal del orquestador
â”œâ”€â”€ cleanup.log                   # Log de limpieza
â”œâ”€â”€ discovery.log                 # Log de descubrimiento MySQL
â”œâ”€â”€ users_setup.log               # Log de configuraciÃ³n usuarios
â”œâ”€â”€ clickhouse_setup.log          # Log de creaciÃ³n modelos
â””â”€â”€ orchestrator_execution_*.json # Logs de ejecuciÃ³n detallados
```

### Comandos de Monitoreo

```bash
# Estado general del pipeline
python3 tools/pipeline_status.py

# Verificar conectores
curl http://localhost:8083/connectors

# Ver tÃ³picos de Kafka
docker compose exec kafka kafka-topics --bootstrap-server kafka:9092 --list

# Consultar datos en ClickHouse
docker compose exec clickhouse clickhouse-client --database fgeo_analytics
```

## ğŸ› ï¸ HERRAMIENTAS ADICIONALES

### Scripts Individuales (para uso manual)

```bash
# Limpiar todo desde cero
python3 tools/cleanup_all.py

# Descubrir tablas MySQL
python3 tools/discover_mysql_tables.py

# Configurar usuarios y permisos
python3 tools/setup_database_users.py

# Crear modelos ClickHouse
python3 tools/create_clickhouse_models.py

# Aplicar conectores
python3 tools/apply_connectors_auto.py

# Validar pipeline completo
python3 tools/validate_etl_complete.py
```

### GestiÃ³n de Servicios

```bash
# Ver estado de servicios
docker compose ps

# Ver logs de un servicio especÃ­fico
docker compose logs -f clickhouse
docker compose logs -f kafka
docker compose logs -f connect

# Reiniciar un servicio
docker compose restart clickhouse

# Detener todo
docker compose down

# Limpiar volÃºmenes (Â¡CUIDADO!)
docker compose down -v
```

## ğŸŒ ACCESO A SERVICIOS

| Servicio | URL | Credenciales |
|----------|-----|--------------|
| **Superset** | http://localhost:8088 | admin / Admin123! |
| **ClickHouse** | http://localhost:8123 | default / (sin password) |
| **Kafka Connect** | http://localhost:8083 | - |
| **Kafka** | localhost:19092 | - |

## ğŸš¨ SOLUCIÃ“N DE PROBLEMAS

### Problemas Comunes

#### 1. Error de conexiÃ³n MySQL
```bash
# Verificar conectividad
ping host.docker.internal
telnet host.docker.internal 3306

# Verificar credenciales
mysql -h host.docker.internal -u root -p
```

#### 2. Servicios no inician
```bash
# Verificar puertos ocupados
ss -tuln | grep -E ':8088|:8123|:8083|:19092'

# Limpiar y reiniciar
docker compose down
docker system prune -f
./start_etl_pipeline.sh --clean
```

#### 3. OrquestaciÃ³n falla
```bash
# Ver logs detallados
tail -f logs/orchestrator.log

# Ejecutar fases individualmente
python3 tools/cleanup_all.py
python3 tools/setup_database_users.py
# ... continuar con otras fases
```

#### 4. Datos no fluyen
```bash
# Verificar estado conectores
curl http://localhost:8083/connectors/mysql_source_auto/status

# Ver tÃ³picos Kafka
docker compose exec kafka kafka-topics --bootstrap-server kafka:9092 --list

# Verificar logs de Connect
docker compose logs connect
```

### Logs de DepuraciÃ³n

Para debugging avanzado, habilitar logs DEBUG:

```bash
# Editar cualquier script Python y cambiar:
logging.basicConfig(level=logging.DEBUG)
```

## ğŸ“š DOCUMENTACIÃ“N ADICIONAL

- [GuÃ­a de Dependencias](docs/DEPENDENCIES.md)
- [Variables de Entorno](docs/ENVIRONMENT_VARIABLES.md)  
- [RecuperaciÃ³n de Errores](docs/ERROR_RECOVERY.md)
- [Referencia RÃ¡pida](docs/QUICK_REFERENCE.md)
- [GuÃ­a de Testing](docs/TESTING_GUIDE.md)

## ğŸ¤ CONTRIBUIR

1. Fork el repositorio
2. Crear rama feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit cambios (`git commit -am 'Agregar nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`) 
5. Crear Pull Request

## ğŸ“„ LICENCIA

Este proyecto estÃ¡ bajo la licencia MIT. Ver archivo `LICENSE` para detalles.

---

## ğŸ‰ Â¡LISTO!

Con un solo comando tienes un pipeline ETL completamente funcional:

```bash
./start_etl_pipeline.sh
```

**Â¡Tu datos fluyen automÃ¡ticamente desde MySQL hasta ClickHouse con visualizaciÃ³n en Superset!** ğŸš€