
networks:
  etl_net:
    external: true
    name: etl_prod_etl_net

volumes:
  ch_data:
  kafka_data:
  connect_data:
  superset_home:

services:
# ---------- ETL TOOLS (ingest_runner) ----------
  # ---------- GENERADOR DE PIPELINE ----------
  etl-tools:
    build:
      context: .
      dockerfile: tools/Dockerfile.pipeline-gen
    image: etl-tools:latest
    container_name: etl-tools
    working_dir: /app
    env_file:
      - .env
    environment:
      - CONNECT_URL=http://connect:8083
      - CLICKHOUSE_URL=http://clickhouse:8123
      - CLICKHOUSE_DATABASE=${CLICKHOUSE_DATABASE:-fgeo_analytics}
      - DB_CONNECTIONS=${DB_CONNECTIONS}
    networks:
      - etl_net
    volumes:
      - ./tools:/app/tools
      - ./logs:/app/logs
      - ./generated:/app/generated
    user: "1000:1000"
    depends_on:
      clickhouse:
        condition: service_healthy
      connect:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "test -d /app/tools && python3 --version || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 3
    restart: no
  pipeline-gen:
    build:
      context: .
      dockerfile: tools/Dockerfile.pipeline-gen
    image: pipeline-gen:latest
    container_name: pipeline-gen
    working_dir: /app
    env_file:
      - .env
    environment:
      - CONNECT_URL=http://connect:8083
      - CLICKHOUSE_URL=http://clickhouse:8123
      - CLICKHOUSE_DATABASE=${CLICKHOUSE_DATABASE:-fgeo_analytics}
      - DB_CONNECTIONS=${DB_CONNECTIONS}
    networks:
      - etl_net
    volumes:
      - ./tools:/app/tools
      - ./logs:/app/logs
    user: "1000:1000"
    entrypoint: ["bash","-lc"]
    command: >
      set -euo pipefail;
      python tools/gen_pipeline.py;
      bash generated/default/ch_create_raw_pipeline.sh;
    depends_on:
      clickhouse:
        condition: service_healthy
      connect:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "test -d /app/tools && python3 --version || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 3
    restart: no

  # ---------- CLICKHOUSE ----------
  clickhouse:
    image: clickhouse/clickhouse-server:24.3
    container_name: clickhouse
    networks:
      - etl_net
    environment:
      - CLICKHOUSE_DB=${CLICKHOUSE_DATABASE:-fgeo_analytics}
      - CLICKHOUSE_USER=default
      - CLICKHOUSE_PASSWORD=
    ports:
      - "8123:8123"     # HTTP
      - "9000:9000"     # Native
    volumes:
      - ch_data:/var/lib/clickhouse
      - ./bootstrap/clickhouse_init.sql:/docker-entrypoint-initdb.d/00_init.sql:ro
    healthcheck:
      test: ["CMD-SHELL", "wget -qO- http://localhost:8123/ping | grep -q 'Ok'"]
      interval: 10s
      timeout: 5s
      retries: 12
    restart: no

  # ---------- SUPERSET ----------
  superset:
    build:
      context: .
      dockerfile: ./superset.Dockerfile
    container_name: superset
    networks:
      - etl_net
    environment:
      - SUPERSET_ENV=production
      - SUPERSET_LOAD_EXAMPLES=no
      - SUPERSET_SECRET_KEY=please_change_me
    volumes:
      - superset_home:/app/superset_home
      - ./superset_bootstrap:/bootstrap:ro
    ports:
      - "8088:8088"
    depends_on:
      clickhouse:
        condition: service_healthy
      superset-venv-setup:
        condition: service_completed_successfully
    command: ["superset", "run", "-p", "8088", "--host", "0.0.0.0"]
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:8088/health || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 30
    restart: no

  # ---------- SUPERSET VENV SETUP ----------
  superset-venv-setup:
    image: python:3.11-slim
    container_name: superset-venv-setup
    user: "0:0"
    working_dir: /app/tools
    volumes:
      - ./tools:/app/tools
      - superset_home:/app/superset_home
    entrypoint: ["python", "setup_superset_venv.py"]
    healthcheck:
      test: ["CMD-SHELL", "test -f /app/superset_home/.venv/bin/activate && /app/superset_home/.venv/bin/python --version && echo 'venv ok' || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 10
    restart: no

  # ---------- SUPERSET INIT ----------
  superset-init:
    image: apache/superset:3.1.0
    container_name: superset-init
    networks:
      - etl_net
    environment:
      - SUPERSET_ADMIN=${SUPERSET_ADMIN:-admin}
      - SUPERSET_PASSWORD=${SUPERSET_PASSWORD:-Admin123!}
    depends_on:
      superset:
        condition: service_healthy
    entrypoint: ["/bin/sh","-lc"]
    command: >
      set -e;
      superset fab create-admin --username "$SUPERSET_ADMIN" --firstname Admin --lastname User --email admin@example.com --password "$SUPERSET_PASSWORD" || true;
      superset db upgrade;
      superset init;
      superset import-datasources -p /bootstrap/clickhouse_db.yaml || true;
      echo SUPerset_INIT_OK;
    restart: no

  # ---------- KAFKA (Confluent, KRaft 1 nodo combinado) ----------
  kafka:
    image: confluentinc/cp-kafka:8.0.1
    container_name: kafka
    networks:
      - etl_net
    ports:
      - "19092:19092"   # acceso desde host
    environment:
      - CLUSTER_ID=${KAFKA_CLUSTER_ID:-MkU3OEVBNTcwNTJENDM2Qk}
      - KAFKA_NODE_ID=1
      - KAFKA_PROCESS_ROLES=broker,controller
      - KAFKA_CONTROLLER_QUORUM_VOTERS=1@kafka:9093
      - KAFKA_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093,PLAINTEXT_HOST://0.0.0.0:19092
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092,PLAINTEXT_HOST://host.docker.internal:19092
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      - KAFKA_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      - KAFKA_AUTO_CREATE_TOPICS_ENABLE=true
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      - KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1
      - KAFKA_TRANSACTION_STATE_LOG_MIN_ISR=1
    volumes:
      - kafka_data:/var/lib/kafka/data
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --bootstrap-server localhost:9092 --list >/dev/null 2>&1"]
      interval: 10s
      timeout: 5s
      retries: 30
    restart: no

  # ---------- KAFKA CONNECT con Debezium ----------
  connect:
    image: debezium/connect:2.6
    container_name: connect
    networks:
      - etl_net
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      - BOOTSTRAP_SERVERS=kafka:9092
      - GROUP_ID=1
      - CONFIG_STORAGE_TOPIC=connect_configs
      - OFFSET_STORAGE_TOPIC=connect_offsets
      - STATUS_STORAGE_TOPIC=connect_statuses
      - KEY_CONVERTER=org.apache.kafka.connect.json.JsonConverter
      - VALUE_CONVERTER=org.apache.kafka.connect.json.JsonConverter
      - REST_ADVERTISED_HOST_NAME=connect
      - REST_PORT=8083
    ports:
      - "8083:8083"
    volumes:
      - connect_data:/kafka
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:8083/connectors >/dev/null"]
      interval: 10s
      timeout: 5s
      retries: 60
    restart: no

  # ---------- CONFIGURADOR (usa tus scripts) ----------
  configurator:
    image: python:3.11-slim
    container_name: configurator
    working_dir: /app
    env_file:
      - .env
    environment:
      - CONNECT_URL=http://connect:8083
      - CLICKHOUSE_URL=http://clickhouse:8123
      - CLICKHOUSE_DATABASE=${CLICKHOUSE_DATABASE:-fgeo_analytics}
      - DB_CONNECTIONS=${DB_CONNECTIONS}
    networks:
      - etl_net
    volumes:
      - ./tools:/app/tools
      - ./superset_bootstrap:/bootstrap:ro
    user: "1000:1000"
    entrypoint: ["bash", "-lc"]
    command: "/app/tools/run_configurator.sh"
    depends_on:
      clickhouse:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "test -d /app/tools && python3 --version || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 3
    restart: no

  # ---------- BOOTSTRAP CDC automático (one-shot) ----------
  cdc-bootstrap:
    image: python:3.11-slim
    container_name: cdc-bootstrap
    working_dir: /app
    env_file:
      - .env
    environment:
      - CONNECT_URL=http://connect:8083
      - CLICKHOUSE_URL=http://clickhouse:8123
      - CLICKHOUSE_DATABASE=${CLICKHOUSE_DATABASE:-fgeo_analytics}
      - DB_CONNECTIONS=${DB_CONNECTIONS}
      - CLICKHOUSE_HTTP_HOST=clickhouse
      - CLICKHOUSE_HTTP_PORT=8123
      - CLICKHOUSE_DATABASE=fgeo_analytics
      - CH_USER=etl
      - CH_PASSWORD=Et1Ingest!
    networks:
      - etl_net
    volumes:
      - ./tools:/app/tools
    depends_on:
      connect:
        condition: service_healthy
      clickhouse:
        condition: service_healthy
    user: "1000:1000"
    entrypoint:
      - python
      - tools/cdc_bootstrap.py
    healthcheck:
      test: ["CMD-SHELL", "test -d /app/tools && python3 --version || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 3
    restart: no

  # ---------- CDC (ejecución directa) ----------
  cdc:
    image: python:3.12-slim
    working_dir: /app
    volumes:
      - ./tools:/app/tools:rw
    environment:
      - CLICKHOUSE_HTTP_HOST=clickhouse
      - CLICKHOUSE_HTTP_PORT=8123
      - CLICKHOUSE_DATABASE=fgeo_analytics
      - CH_USER=etl
      - CH_PASSWORD=Et1Ingest!
    depends_on:
      clickhouse:
        condition: service_healthy
    entrypoint:
      - python
      - tools/cdc_bootstrap.py
    healthcheck:
      test: ["CMD-SHELL", "test -d /app/tools && python3 --version || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 3
    restart: no



  # ---------- APLICACIÓN AUTOMÁTICA DE CONECTORES ----------
  connector-applier:
    build:
      context: .
      dockerfile: tools/Dockerfile.pipeline-gen
    image: etl-tools:latest
    container_name: connector-applier
    working_dir: /app
    env_file:
      - .env
    environment:
      - CONNECT_URL=http://connect:8083
    networks:
      - etl_net
    volumes:
      - ./tools:/app/tools
      - ./generated:/app/generated
      - ./logs:/app/logs
    user: "1000:1000"
    depends_on:
      connect:
        condition: service_healthy
    command: ["python", "tools/apply_connectors_auto.py"]
    restart: no
