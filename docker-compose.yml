
networks:
# [RECOMENDACIÓN IMPORTANTE]
# Para que la reparación automática del socket Docker funcione:
# 1. El host debe permitir la modificación de grupos y usuarios dentro del contenedor (privileged: true).
# 2. El socket Docker debe estar montado: /var/run/docker.sock:/var/run/docker.sock
# 3. El grupo docker debe ser añadido dinámicamente: group_add: ["${DOCKER_GID:-999}"]
# 4. El usuario debe ser el mismo que el grupo docker: user: "1000:1000"
# 5. Si usas WSL2, Docker Desktop o entornos cloud, asegúrate que el usuario del host tiene permisos sobre el socket.
# 6. Si el entorno no permite modificar grupos, la reparación automática no funcionará y deberás configurar el host antes de levantar los contenedores.
# 7. Puedes consultar docs/ERROR_RECOVERY.md para más detalles y soluciones específicas.
  etl_net:
    # [DOCUMENTACIÓN] La red 'etl_net' es gestionada automáticamente por Docker Compose.
    # Se elimina 'external: true' para evitar conflictos y asegurar que Compose cree y elimine la red según el ciclo del pipeline.
    # Esto garantiza que todos los servicios se comuniquen correctamente y la limpieza no afecte recursos externos.
    name: etl_prod_etl_net
volumes:
  ch_data:
  kafka_data:
  connect_data:
  superset_home:
  etl_logs:

services:
# ---------- ETL TOOLS (ingest_runner) ----------
  # ---------- GENERADOR DE PIPELINE ----------
  # ---------- ORQUESTADOR MAESTRO CENTRALIZADO ----------
  etl-orchestrator:
    build:
      context: .
      dockerfile: tools/Dockerfile.pipeline-gen
    env_file:
      - .env
    environment:
      - CLICKHOUSE_HOST=clickhouse
      - CLICKHOUSE_HTTP_PORT=8123
      - CLICKHOUSE_TCP_PORT=9000
      - CLICKHOUSE_USER=${CLICKHOUSE_ETL_USER:-etl}
      - CLICKHOUSE_PASSWORD=${CLICKHOUSE_ETL_PASSWORD:-Et1Ingest!}
      - CLICKHOUSE_DATABASE=${CLICKHOUSE_DATABASE:-fgeo_analytics}
      - SUPERSET_URL=http://superset:8088
      - SUPERSET_USERNAME=admin
      - SUPERSET_PASSWORD=admin
      - PYTHONUNBUFFERED=1
    volumes:
      - ./tools:/app/tools
      - ./logs:/app/logs
      - ./generated:/app/generated
      - ./superset_bootstrap:/app/superset_bootstrap
      - ./.env:/app/.env:ro
      - /var/run/docker.sock:/var/run/docker.sock  # Acceso al socket Docker
    privileged: true
    group_add:
      - "${DOCKER_GID:-999}"  # GID dinámico del grupo docker
    depends_on:
      clickhouse:
        condition: service_healthy
      connect:
        condition: service_healthy
      kafka:
        condition: service_started
      superset:
        condition: service_healthy
    command: ["bash", "/app/tools/auto_pipeline.sh"]
    healthcheck:
      test: ["CMD-SHELL", "test -f /app/logs/auto_pipeline_status.json || exit 1"]
      interval: 60s
      timeout: 30s
      retries: 5
      start_period: 60s
    restart: "no"  # Solo ejecuta una vez
    networks:
      - etl_net
  
  # ---------- HERRAMIENTAS ETL (para ejecución de scripts) ----------
  etl-tools:
    build:
      context: .
      dockerfile: tools/Dockerfile.pipeline-gen
    image: etl-tools:latest
    container_name: etl-tools
    working_dir: /app
    env_file:
      - .env
      - .env.docker  # GID dinámico del grupo docker
    environment:
      - CONNECT_URL=http://connect:8083
      - CLICKHOUSE_URL=http://clickhouse:8123
      - CLICKHOUSE_DATABASE=${CLICKHOUSE_DATABASE:-fgeo_analytics}
      - DB_CONNECTIONS=${DB_CONNECTIONS}
      - PYTHONUNBUFFERED=1
      - RUNNING_IN_DOCKER=1
    networks:
      - etl_net
    volumes:
      - ./tools:/app/tools
      - ./logs:/app/logs
      - ./generated:/app/generated
      - ./bootstrap:/app/bootstrap
      - ./superset_bootstrap:/app/superset_bootstrap
      - /var/run/docker.sock:/var/run/docker.sock  # Acceso directo al socket Docker
      - ./.env:/app/.env
    privileged: true
    # Grupo docker dinámico basado en el GID del host
    group_add:
      - "${DOCKER_GID:-999}"  # GID dinámico del grupo docker
    user: "1000:1000"
    depends_on:
      clickhouse:
        condition: service_healthy
      connect:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "test -d /app/tools && python3 --version && docker --version || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 3
  pipeline-gen:
    build:
      context: .
      dockerfile: tools/Dockerfile.pipeline-gen
    image: pipeline-gen:latest
    container_name: pipeline-gen
    working_dir: /app
    env_file:
      - .env
    environment:
      - CONNECT_URL=http://connect:8083
      - CLICKHOUSE_URL=http://clickhouse:8123
      - CLICKHOUSE_DATABASE=${CLICKHOUSE_DATABASE:-fgeo_analytics}
      - DB_CONNECTIONS=${DB_CONNECTIONS}
      - PYTHONUNBUFFERED=1
    networks:
      - etl_net
    volumes:
      - ./tools:/app/tools
      - ./logs:/app/logs
      - ./generated:/app/generated
      - /var/run/docker.sock:/var/run/docker.sock  # Acceso directo al socket Docker
    privileged: true
    # Grupo docker dinámico basado en el GID del host
    group_add:
      - "${DOCKER_GID:-999}"  # GID dinámico del grupo docker
    user: "1000:1000"
    entrypoint: ["/bin/bash", "-c", "mkdir -p /app/generated/default && chmod -R 777 /app/generated && python3 /app/tools/gen_pipeline.py && tail -f /dev/null"]
    depends_on:
      clickhouse:
        condition: service_healthy
      connect:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "test -d /app/tools && python3 --version && docker --version || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 3

  # ---------- CLICKHOUSE ----------
  clickhouse:
    build:
      context: .
      dockerfile: clickhouse.Dockerfile
    container_name: clickhouse
    networks:
      - etl_net
    env_file:
      - .env
    environment:
      - CLICKHOUSE_DB=${CLICKHOUSE_DATABASE:-fgeo_analytics}
      - CLICKHOUSE_DEFAULT_ACCESS_MANAGEMENT=1
      - CLICKHOUSE_PASSWORD=ClickHouse123!
      - CLICKHOUSE_USER=default
      - CLICKHOUSE_HTTP_HOST=clickhouse
      - CLICKHOUSE_HTTP_PORT=8123
      - CLICKHOUSE_NATIVE_PORT=9000
    ports:
      - "8123:8123"     # HTTP
      - "9000:9000"     # Native TCP (para Python driver)
    volumes:
      - ./bootstrap:/app:ro
      - ./bootstrap/clickhouse_init.sql:/docker-entrypoint-initdb.d/00_init.sql:ro
      - ./bootstrap/create_users.sql:/docker-entrypoint-initdb.d/01_create_users.sql:ro
      - ./bootstrap/users.xml:/app/users.xml:ro
      - ./bootstrap/setup_users_automatically.sh:/docker-entrypoint-initdb.d/02_setup_users.sh:ro
    healthcheck:
      test: ["CMD-SHELL", "clickhouse-client --password=ClickHouse123! --query='SELECT 1' || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 12

  # ---------- CLICKHOUSE MULTI-DATABASE SETUP ----------
  clickhouse-setup:
    build:
      context: .
      dockerfile: tools/Dockerfile.pipeline-gen
    image: etl-tools:latest
    container_name: clickhouse-setup
    working_dir: /app
    networks:
      - etl_net
    env_file:
      - .env
    environment:
      - CLICKHOUSE_HTTP_HOST=clickhouse
      - CLICKHOUSE_HTTP_PORT=8123
      - CLICKHOUSE_NATIVE_PORT=9000
      - CH_USER=etl
      - CH_PASSWORD=Et1Ingest!
      - CH_DB=fgeo_analytics
      - DB_CONNECTIONS=${DB_CONNECTIONS}
    volumes:
      - ./tools:/app/tools
      - ./bootstrap:/app/bootstrap:ro
      - ./logs:/app/logs
      - /var/run/docker.sock:/var/run/docker.sock  # Para comandos docker
    depends_on:
      clickhouse:
        condition: service_healthy
    command: ["python3", "tools/setup_clickhouse_complete.py"]

  # ---------- SUPERSET ----------
  superset:
    build:
      context: .
      dockerfile: ./superset.Dockerfile
    container_name: superset
    networks:
      - etl_net
    environment:
      - SUPERSET_ENV=production
      - SUPERSET_LOAD_EXAMPLES=no
      - SUPERSET_SECRET_KEY=Sup3rS3cr3tK3yF0rPr0duct10nUs3
    volumes:
      - superset_home:/app/superset_home
      - ./superset_bootstrap:/bootstrap:ro
      - ./generated/default/schemas:/app/generated/default/schemas:ro
    ports:
      - "8088:8088"
    depends_on:
      clickhouse:
        condition: service_healthy
      superset-venv-setup:
        condition: service_completed_successfully
    command: ["superset", "run", "-p", "8088", "--host", "0.0.0.0"]
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:8088/health || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 30

  # ---------- SUPERSET VENV SETUP ----------
  superset-venv-setup:
    image: python:3.11-slim
    container_name: superset-venv-setup
    user: "0:0"
    working_dir: /app/tools
    volumes:
      - ./tools:/app/tools
      - superset_home:/app/superset_home
    entrypoint: ["python", "setup_superset_venv.py"]
    healthcheck:
      test: ["CMD-SHELL", "test -f /app/superset_home/.venv/bin/activate && /app/superset_home/.venv/bin/python --version && echo 'venv ok' || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 10

  # ---------- SUPERSET INIT ----------
  superset-init:
    build:
      context: .
      dockerfile: tools/Dockerfile.pipeline-gen
    image: etl-tools:latest
    container_name: superset-init
    working_dir: /app
    networks:
      - etl_net
    env_file:
      - .env
    environment:
      - SUPERSET_URL=http://superset:8088
      - SUPERSET_ADMIN=${SUPERSET_ADMIN:-admin}
      - SUPERSET_PASSWORD=${SUPERSET_PASSWORD:-Admin123!}
      - CLICKHOUSE_URL=http://clickhouse:8123
      - CLICKHOUSE_DATABASE=${CLICKHOUSE_DATABASE:-fgeo_analytics}
    volumes:
      - ./tools:/app/tools
      - ./superset_bootstrap:/bootstrap:ro
      - ./logs:/app/logs
      - /var/run/docker.sock:/var/run/docker.sock  # Para comandos docker
    depends_on:
      superset:
        condition: service_healthy
      etl-orchestrator:
        condition: service_completed_successfully
    command: ["python3", "tools/superset_auto_configurator.py"]

  # ---------- SUPERSET DATASET CONFIGURATOR ----------
  superset-datasets:
    image: apache/superset:latest
    container_name: superset-datasets
    depends_on:
      - superset
      - clickhouse
    volumes:
      - ./superset_bootstrap:/bootstrap
    environment:
      - SUPERSET_URL=http://superset:8088
      - SUPERSET_ADMIN=admin
      - SUPERSET_PASSWORD=Admin123!
      - CLICKHOUSE_HTTP_HOST=clickhouse
      - CLICKHOUSE_HTTP_PORT=8123
      - CLICKHOUSE_USER=superset
      - CLICKHOUSE_PASSWORD=Sup3rS3cret!
      - DB_CONNECTIONS=${DB_CONNECTIONS}
    command: "bash -c 'echo \"🔧 Instalando dependencias...\" && pip install requests && echo \"📊 Iniciando configuración multi-database...\" && python /bootstrap/multi_database_configurator.py'"
    networks:
      - etl_net

  # ---------- MULTI-DATABASE AUDITOR ----------
  multi-db-auditor:
    image: python:3.11-slim
    container_name: multi-db-auditor
    working_dir: /app
    environment:
      - CLICKHOUSE_HTTP_HOST=clickhouse
      - CLICKHOUSE_HTTP_PORT=8123
      - CLICKHOUSE_USER=auditor
      - CLICKHOUSE_PASSWORD=Audit0r123!
      - DB_CONNECTIONS=${DB_CONNECTIONS}
    networks:
      - etl_net
    volumes:
      - ./tools:/app/tools
      - ./logs:/tmp/logs
    depends_on:
      clickhouse:
        condition: service_healthy
      clickhouse-setup:
        condition: service_completed_successfully
    command: "bash -c 'echo \"🔧 Instalando dependencias auditor...\" && pip install mysql-connector-python clickhouse-driver pymysql requests && echo \"🔍 Ejecutando auditoría multi-database...\" && python /app/tools/multi_database_auditor.py'"
    profiles:
      - audit  # Solo se ejecuta cuando se especifica el perfil audit

  # ---------- KAFKA (Confluent, KRaft 1 nodo combinado) ----------
  kafka:
    image: confluentinc/cp-kafka:8.0.1
    container_name: kafka
    networks:
      - etl_net
    ports:
      - "19092:19092"   # acceso desde host
    environment:
      - CLUSTER_ID=${KAFKA_CLUSTER_ID:-MkU3OEVBNTcwNTJENDM2Qk}
      - KAFKA_NODE_ID=1
      - KAFKA_PROCESS_ROLES=broker,controller
      - KAFKA_CONTROLLER_QUORUM_VOTERS=1@kafka:9093
      - KAFKA_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093,PLAINTEXT_HOST://0.0.0.0:19092
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092,PLAINTEXT_HOST://host.docker.internal:19092
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      - KAFKA_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      - KAFKA_AUTO_CREATE_TOPICS_ENABLE=true
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      - KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1
      - KAFKA_TRANSACTION_STATE_LOG_MIN_ISR=1
    volumes:
      - kafka_data:/var/lib/kafka/data
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --bootstrap-server localhost:9092 --list >/dev/null 2>&1"]
      interval: 10s
      timeout: 5s
      retries: 30

  # ---------- KAFKA CONNECT con Debezium ----------
  connect:
    image: debezium/connect:2.6
    container_name: connect
    networks:
      - etl_net
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      - BOOTSTRAP_SERVERS=kafka:9092
      - GROUP_ID=1
      - CONFIG_STORAGE_TOPIC=connect_configs
      - OFFSET_STORAGE_TOPIC=connect_offsets
      - STATUS_STORAGE_TOPIC=connect_statuses
      - KEY_CONVERTER=org.apache.kafka.connect.json.JsonConverter
      - VALUE_CONVERTER=org.apache.kafka.connect.json.JsonConverter
      - REST_ADVERTISED_HOST_NAME=connect
      - REST_PORT=8083
    ports:
      - "8083:8083"
    volumes:
      - connect_data:/kafka
    healthcheck:
      test: ["CMD-SHELL", "curl -sf http://localhost:8083/connectors >/dev/null"]
      interval: 10s
      timeout: 5s
      retries: 60

  # ---------- CONFIGURADOR (usa tus scripts) ----------
  configurator:
    image: python:3.11-slim
    container_name: configurator
    working_dir: /app
    env_file:
      - .env
    environment:
      - CONNECT_URL=http://connect:8083
      - CLICKHOUSE_URL=http://clickhouse:8123
      - CLICKHOUSE_DATABASE=${CLICKHOUSE_DATABASE:-fgeo_analytics}
      - DB_CONNECTIONS=${DB_CONNECTIONS}
    networks:
      - etl_net
    volumes:
      - ./tools:/app/tools
      - ./superset_bootstrap:/bootstrap:ro
    user: "1000:1000"
    entrypoint: ["bash", "-lc"]
    command: "/app/tools/run_configurator.sh"
    depends_on:
      clickhouse:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "test -d /app/tools && python3 --version || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 3

  # ---------- BOOTSTRAP CDC automático (one-shot) ----------
  cdc-bootstrap:
    image: python:3.11-slim
    container_name: cdc-bootstrap
    working_dir: /app
    env_file:
      - .env
    environment:
      - CONNECT_URL=http://connect:8083
      - CLICKHOUSE_URL=http://clickhouse:8123
      - CLICKHOUSE_DATABASE=${CLICKHOUSE_DATABASE:-fgeo_analytics}
      - DB_CONNECTIONS=${DB_CONNECTIONS}
      - CLICKHOUSE_HTTP_HOST=clickhouse
      - CLICKHOUSE_HTTP_PORT=8123
      - CH_USER=etl
      - CH_PASSWORD=Et1Ingest!
    networks:
      - etl_net
    volumes:
      - ./tools:/app/tools
    depends_on:
      connect:
        condition: service_healthy
      clickhouse:
        condition: service_healthy
    user: "1000:1000"
    entrypoint:
      - python
      - tools/cdc_bootstrap.py
    healthcheck:
      test: ["CMD-SHELL", "test -d /app/tools && python3 --version || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 3

  # ---------- CDC (ejecución directa) ----------
  cdc:
    image: python:3.12-slim
    working_dir: /app
    volumes:
      - ./tools:/app/tools:rw
    environment:
      - CLICKHOUSE_HTTP_HOST=clickhouse
      - CLICKHOUSE_HTTP_PORT=8123
      - CLICKHOUSE_DATABASE=fgeo_analytics
      - CH_USER=etl
      - CH_PASSWORD=Et1Ingest!
    depends_on:
      clickhouse:
        condition: service_healthy
    entrypoint:
      - python
      - tools/cdc_bootstrap.py
    healthcheck:
      test: ["CMD-SHELL", "test -d /app/tools && python3 --version || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 3




  # ---------- APLICACIÓN AUTOMÁTICA DE CONECTORES (LEGACY - Mantenido para compatibilidad) ----------
  connector-applier:
    build:
      context: .
      dockerfile: tools/Dockerfile.pipeline-gen
    image: etl-tools:latest
    container_name: connector-applier
    working_dir: /app
    env_file:
      - .env
    environment:
      - CONNECT_URL=http://connect:8083
    networks:
      - etl_net
    volumes:
      - ./tools:/app/tools
      - ./generated:/app/generated
      - ./logs:/app/logs
    user: "1000:1000"
    depends_on:
      connect:
        condition: service_healthy
    command: ["python", "tools/apply_connectors_auto.py"]
    profiles:
      - manual  # Solo se ejecuta si se especifica el perfil manual
