#!/usr/bin/env python3
"""
orchestrate_etl_init.py
Orquestador maestro del pipeline ETL. Ejecuta todas las fases de inicializaciÃ³n y validaciÃ³n, maneja reintentos automÃ¡ticos y asegura la secuencia correcta de pasos.
EjecuciÃ³n recomendada: Servicio Docker (`etl-orchestrator`).

FASES PRINCIPALES:
1. Limpieza completa
2. ConfiguraciÃ³n de usuarios
3. Descubrimiento de esquemas
4. Despliegue de conectores
5. ValidaciÃ³n completa
"""

import subprocess
import time
import json
import logging
import os
import sys
from datetime import datetime
from typing import Dict, List, Tuple, Optional, Any

# Configurar logging centralizado
class ColoredFormatter(logging.Formatter):
    """Formatter con colores para diferentes niveles de log"""
    
    COLORS = {
        'DEBUG': '\033[36m',    # Cyan
        'INFO': '\033[32m',     # Green
        'WARNING': '\033[33m',  # Yellow
        'ERROR': '\033[31m',    # Red
        'CRITICAL': '\033[35m', # Magenta
        'RESET': '\033[0m'      # Reset
    }
    
    def format(self, record):
        log_color = self.COLORS.get(record.levelname, self.COLORS['RESET'])
        reset_color = self.COLORS['RESET']
        
        # Formato con color
        formatter = logging.Formatter(
            f'{log_color}%(asctime)s - %(name)s - %(levelname)s{reset_color} - %(message)s'
        )
        return formatter.format(record)

# Configurar logging
def setup_logging():
    """Configurar sistema de logging completo"""
    # Detectar si estamos en contenedor Docker
    in_docker = os.path.exists('/.dockerenv') or os.environ.get('RUNNING_IN_DOCKER') == '1'
    log_dir = '/app/logs' if in_docker else './logs'
    os.makedirs(log_dir, exist_ok=True)
    
    # Logger principal
    logger = logging.getLogger('ETL_ORCHESTRATOR')
    logger.setLevel(logging.INFO)
    
    # Handler para archivo
    file_handler = logging.FileHandler(f'{log_dir}/orchestrator.log')
    file_handler.setLevel(logging.DEBUG)
    file_formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    file_handler.setFormatter(file_formatter)
    
    # Handler para consola con colores
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(logging.INFO)
    console_handler.setFormatter(ColoredFormatter())
    
    # Agregar handlers
    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    
    return logger

logger = setup_logging()

class ETLOrchestrator:
    def __init__(self):
        self.start_time = datetime.now()
        self.phases = []
        self.current_phase = None
        
        # ConfiguraciÃ³n de fases
        self.phase_config = {
            'pipeline_gen': {
                'name': 'ğŸ—ï¸ GENERACIÃ“N DE PIPELINE',
                'script': 'gen_pipeline.py',
                'description': 'Generar configuraciones de conectores y esquemas',
                'required': True,
                'timeout': 120,
                'retries': 3,
                'retry_delay': 10
            },
            'connectors': {
                'name': 'ğŸ”Œ DESPLIEGUE DE CONECTORES',
                'script': 'apply_connectors_auto.py',
                'description': 'Aplicar conectores Debezium automÃ¡ticamente',
                'required': True,
                'timeout': 180,
                'retries': 3,
                'retry_delay': 15
            },
            'validation': {
                'name': 'âœ… VALIDACIÃ“N COMPLETA',
                'script': 'pipeline_status.py',
                'description': 'Verificar flujo completo de datos',
                'required': False,  # No crÃ­tico - permite continuar aunque falle
                'timeout': 60,
                'retries': 2,
                'retry_delay': 10
            }
        }
        
        # Estado del orquestador
        self.status = {
            'start_time': self.start_time.isoformat(),
            'phases_completed': 0,
            'phases_total': len(self.phase_config),
            'current_phase': None,
            'success': False,
            'errors': [],
            'execution_time': 0
        }
    
    def wait_for_services(self) -> bool:
        """Esperar a que todos los servicios estÃ©n disponibles"""
        logger.info("â³ Esperando servicios crÃ­ticos...")
        
        services = {
            'connect': 'curl -s http://connect:8083/ -m 5',
            'clickhouse': 'curl -s http://clickhouse:8123/ping -m 5'
        }
        
        max_wait = 180  # 3 minutos mÃ¡ximo
        start_wait = time.time()
        
        for service_name, check_cmd in services.items():
            logger.info(f"ğŸ” Verificando servicio: {service_name}")
            service_ready = False
            service_wait_start = time.time()
            
            while not service_ready and (time.time() - start_wait) < max_wait:
                try:
                    result = subprocess.run(
                        check_cmd,
                        shell=True,
                        capture_output=True,
                        text=True,
                        timeout=10
                    )
                    
                    if result.returncode == 0:
                        logger.info(f"âœ… Servicio {service_name} disponible")
                        service_ready = True
                    else:
                        elapsed = time.time() - service_wait_start
                        logger.debug(f"â³ Esperando {service_name}... ({elapsed:.1f}s)")
                        time.sleep(5)
                        
                except subprocess.TimeoutExpired:
                    logger.debug(f"â³ Timeout verificando {service_name}, reintentando...")
                    time.sleep(5)
                except Exception as e:
                    logger.debug(f"â³ Error verificando {service_name}: {str(e)}")
                    time.sleep(5)
                    
            if not service_ready:
                logger.error(f"âŒ Servicio {service_name} no disponible despuÃ©s de {max_wait}s")
                return False
                
        # Verificar que el directorio /app/generated existe y estÃ¡ accesible
        logger.info("ğŸ” Verificando acceso a directorios de trabajo...")
        if not os.path.exists('/app/generated'):
            logger.info("ğŸ“ Creando directorio /app/generated...")
            os.makedirs('/app/generated/default', exist_ok=True)
            
        # Verificar acceso a herramientas
        tools_dir = '/app/tools'
        if not os.path.exists(tools_dir):
            logger.error(f"âŒ Directorio de herramientas no encontrado: {tools_dir}")
            return False
            
        total_wait = time.time() - start_wait
        logger.info(f"âœ… Servicios crÃ­ticos disponibles ({total_wait:.1f}s)")
        return True
    
    def execute_phase(self, phase_key: str) -> bool:
        """Ejecutar una fase especÃ­fica con reintentos automÃ¡ticos"""
        phase = self.phase_config[phase_key]
        self.current_phase = phase_key
        self.status['current_phase'] = phase['name']

        logger.info(f"\n{'='*80}")
        logger.info(f"ğŸš€ INICIANDO FASE: {phase['name']}")
        logger.info(f"ğŸ“‹ DescripciÃ³n: {phase['description']}")
        logger.info(f"ğŸ”§ Script: {phase['script']}")
        logger.info(f"ğŸ” Reintentos permitidos: {phase.get('retries', 1)}")
        logger.info(f"{'='*80}")

        max_retries = phase.get('retries', 1)
        retry_delay = phase.get('retry_delay', 10)
        attempt = 0
        phase_start = time.time()

        while attempt < max_retries:
            attempt += 1
            logger.info(f"â–¶ï¸  Intento {attempt}/{max_retries} de fase: {phase['name']}")
            try:
                cmd = f"cd /app && python3 tools/{phase['script']}"
                result = subprocess.run(
                    cmd,
                    shell=True,
                    capture_output=True,
                    text=True,
                    timeout=phase['timeout']
                )
                phase_duration = time.time() - phase_start

                if result.returncode == 0:
                    logger.info(f"âœ… FASE COMPLETADA: {phase['name']} en intento {attempt} ({phase_duration:.1f}s)")
                    if result.stdout.strip():
                        logger.debug("ğŸ“¤ Salida del script:")
                        for line in result.stdout.strip().split('\n')[-10:]:
                            logger.debug(f"   {line}")
                    self.status['phases_completed'] += 1
                    return True
                else:
                    logger.error(f"âŒ FASE FALLÃ“: {phase['name']} (cÃ³digo: {result.returncode}) en intento {attempt}")
                    if result.stderr.strip():
                        logger.error("ğŸ“¤ Error del script:")
                        for line in result.stderr.strip().split('\n')[-10:]:
                            logger.error(f"   {line}")
                    error_info = {
                        'phase': phase['name'],
                        'script': phase['script'],
                        'return_code': result.returncode,
                        'error': result.stderr.strip()[-500:] if result.stderr.strip() else 'No error output',
                        'duration': phase_duration,
                        'attempt': attempt
                    }
                    self.status['errors'].append(error_info)
                    if attempt < max_retries:
                        logger.info(f"â³ Esperando {retry_delay}s antes de reintentar...")
                        time.sleep(retry_delay)
            except subprocess.TimeoutExpired:
                phase_duration = time.time() - phase_start
                logger.error(f"â° FASE TIMEOUT: {phase['name']} ({phase['timeout']}s) en intento {attempt}")
                error_info = {
                    'phase': phase['name'],
                    'script': phase['script'],
                    'error': f'Timeout despuÃ©s de {phase["timeout"]}s',
                    'duration': phase_duration,
                    'attempt': attempt
                }
                self.status['errors'].append(error_info)
                if attempt < max_retries:
                    logger.info(f"â³ Esperando {retry_delay}s antes de reintentar...")
                    time.sleep(retry_delay)
            except Exception as e:
                phase_duration = time.time() - phase_start
                logger.error(f"ğŸ’¥ FASE ERROR: {phase['name']} - {str(e)} en intento {attempt}")
                error_info = {
                    'phase': phase['name'],
                    'script': phase['script'],
                    'error': str(e),
                    'duration': phase_duration,
                    'attempt': attempt
                }
                self.status['errors'].append(error_info)
                if attempt < max_retries:
                    logger.info(f"â³ Esperando {retry_delay}s antes de reintentar...")
                    time.sleep(retry_delay)

        # Si no se logrÃ³ completar la fase despuÃ©s de los reintentos
        logger.error(f"âŒ FASE NO SUPERADA: {phase['name']} tras {max_retries} intentos")
        return not phase['required']
    
    def save_execution_log(self):
        """Guardar log completo de ejecuciÃ³n"""
        try:
            self.status['end_time'] = datetime.now().isoformat()
            self.status['execution_time'] = (datetime.now() - self.start_time).total_seconds()
            
            log_file = f"/app/logs/orchestrator_execution_{self.start_time.strftime('%Y%m%d_%H%M%S')}.json"
            
            with open(log_file, 'w') as f:
                json.dump(self.status, f, indent=2)
            
            logger.info(f"ğŸ’¾ Log de ejecuciÃ³n guardado: {log_file}")
            
        except Exception as e:
            logger.error(f"âŒ Error guardando log de ejecuciÃ³n: {str(e)}")
    
    def print_final_summary(self):
        """Imprimir resumen final de la ejecuciÃ³n"""
        end_time = datetime.now()
        total_duration = (end_time - self.start_time).total_seconds()
        
        print(f"\n{'='*80}")
        print(f"ğŸ RESUMEN FINAL DE INICIALIZACIÃ“N AUTOMÃTICA")
        print(f"{'='*80}")
        print(f"â° Inicio: {self.start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"â° Fin: {end_time.strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"â±ï¸  DuraciÃ³n total: {total_duration:.1f} segundos")
        print(f"ğŸ“Š Fases completadas: {self.status['phases_completed']}/{self.status['phases_total']}")
        
        if self.status['success']:
            print(f"\nğŸ‰ INICIALIZACIÃ“N EXITOSA")
            print(f"âœ… Pipeline ETL completamente funcional")
            print(f"ğŸš€ Sistema listo para operaciÃ³n")
        else:
            print(f"\nâš ï¸  INICIALIZACIÃ“N PARCIAL O FALLIDA")
            print(f"âŒ {len(self.status['errors'])} errores encontrados")
            
            if self.status['errors']:
                print(f"\nğŸ” ERRORES DETALLADOS:")
                for i, error in enumerate(self.status['errors'], 1):
                    print(f"   {i}. {error['phase']}: {error['error'][:100]}...")
        
        print(f"\nğŸ’¡ PRÃ“XIMOS PASOS:")
        if self.status['success']:
            print(f"   1. Verificar datos: python3 tools/pipeline_status.py")
            print(f"   2. Configurar Superset para visualizaciÃ³n")
            print(f"   3. Configurar monitoreo y alertas")
        else:
            print(f"   1. Revisar logs detallados en /app/logs/")
            print(f"   2. Corregir errores encontrados")
            print(f"   3. Re-ejecutar inicializaciÃ³n")
        
        print(f"{'='*80}")
    
    def run_full_initialization(self) -> bool:
        """Ejecutar inicializaciÃ³n completa del pipeline ETL"""
        logger.info("ğŸ¯ === INICIANDO ORQUESTACIÃ“N AUTOMÃTICA DEL PIPELINE ETL ===")
        logger.info(f"â° Tiempo de inicio: {self.start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info(f"ğŸ“‹ Fases programadas: {len(self.phase_config)}")
        
        try:
            # 1. Esperar servicios
            if not self.wait_for_services():
                logger.error("âŒ Servicios no disponibles, abortando inicializaciÃ³n")
                return False
            
            # 2. Ejecutar fases en orden
            phases_order = ['pipeline_gen', 'connectors', 'validation']
            
            for phase_key in phases_order:
                if not self.execute_phase(phase_key):
                    if self.phase_config[phase_key]['required']:
                        logger.error(f"âŒ Fase requerida fallÃ³: {phase_key}, abortando")
                        self.status['success'] = False
                        return False
                    else:
                        logger.warning(f"âš ï¸  Fase opcional fallÃ³: {phase_key}, continuando")
            
            # 3. Ã‰xito completo
            self.status['success'] = True
            logger.info("ğŸ‰ TODAS LAS FASES COMPLETADAS EXITOSAMENTE")
            return True
            
        except Exception as e:
            logger.error(f"ğŸ’¥ Error crÃ­tico en orquestaciÃ³n: {str(e)}")
            self.status['success'] = False
            return False
        
        finally:
            # Siempre guardar log y mostrar resumen
            self.save_execution_log()
            self.print_final_summary()

def main():
    """FunciÃ³n principal"""
    try:
        # Banner de inicio
        print(f"\n{'='*80}")
        print(f"ğŸ¯ ORQUESTADOR AUTOMÃTICO DEL PIPELINE ETL")
        print(f"ğŸš€ InicializaciÃ³n completa desde cero")
        print(f"â° {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"{'='*80}")
        
        orchestrator = ETLOrchestrator()
        success = orchestrator.run_full_initialization()
        
        return 0 if success else 1
        
    except KeyboardInterrupt:
        logger.info("ğŸ›‘ OrquestaciÃ³n interrumpida por el usuario")
        return 1
    except Exception as e:
        logger.error(f"ğŸ’¥ Error crÃ­tico en main: {str(e)}")
        return 1

if __name__ == "__main__":
    exit(main())