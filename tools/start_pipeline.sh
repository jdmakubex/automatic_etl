#!/bin/bash
set -e

# =============================================================================
# üöÄ SCRIPT DE INICIALIZACI√ìN COMPLETA DEL PIPELINE ETL
# =============================================================================
# Este script ejecuta todo el pipeline ETL usando las configuraciones 
# centralizadas del archivo .env
#
# Uso:
#   ./tools/start_pipeline.sh [--clean] [--validate-only]
#
# Opciones:
#   --clean        : Limpia todos los contenedores y vol√∫menes antes de iniciar
#   --validate-only: Solo valida la configuraci√≥n sin ejecutar el pipeline
# =============================================================================

# Colores para output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Funciones de utilidad
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

print_section() {
    echo
    echo "============================================================"
    echo "üéØ $1"
    echo "============================================================"
}

# Verificar que estamos en el directorio correcto
if [[ ! -f "docker-compose.yml" ]] || [[ ! -f ".env" ]]; then
    log_error "Este script debe ejecutarse desde el directorio ra√≠z del proyecto"
    log_error "Aseg√∫rate de que existan docker-compose.yml y .env"
    exit 1
fi

# Cargar variables de entorno
if [[ -f ".env" ]]; then
    log_info "Cargando configuraci√≥n desde .env..."
    export $(grep -v '^#' .env | xargs)
else
    log_error "Archivo .env no encontrado"
    exit 1
fi

# Procesar argumentos
CLEAN_MODE=false
VALIDATE_ONLY=false

for arg in "$@"; do
    case $arg in
        --clean)
            CLEAN_MODE=true
            shift
            ;;
        --validate-only)
            VALIDATE_ONLY=true
            shift
            ;;
        *)
            log_error "Argumento desconocido: $arg"
            echo "Uso: $0 [--clean] [--validate-only]"
            exit 1
            ;;
    esac
done

# Funci√≥n de validaci√≥n de configuraci√≥n
validate_configuration() {
    print_section "VALIDACI√ìN DE CONFIGURACI√ìN"
    
    if [[ -f "tools/validate_config.py" ]]; then
        log_info "Ejecutando validador de configuraci√≥n..."
        python3 tools/validate_config.py
        if [[ $? -ne 0 ]]; then
            log_error "Validaci√≥n de configuraci√≥n fall√≥"
            exit 1
        fi
    else
        log_warning "Script de validaci√≥n no encontrado, saltando..."
    fi
}

# Funci√≥n de limpieza
clean_environment() {
    print_section "LIMPIEZA DEL ENTORNO"
    
    log_info "Deteniendo todos los servicios..."
    docker compose down --remove-orphans || true
    
    log_info "Eliminando vol√∫menes..."
    docker compose down -v || true
    
    log_info "Limpiando im√°genes no utilizadas..."
    docker system prune -f || true
    
    log_info "Limpiando directorio generated..."
    rm -rf generated/* || true
    mkdir -p generated/default
    
    log_info "Limpiando logs antiguos..."
    rm -rf logs/* || true
    mkdir -p logs
    
    log_success "Entorno limpiado correctamente"
}

# Funci√≥n principal de despliegue
deploy_pipeline() {
    print_section "DESPLIEGUE DEL PIPELINE ETL"
    
    log_info "Construyendo im√°genes..."
    docker compose build --no-cache
    
    log_info "Iniciando servicios en orden de dependencias..."
    docker compose up -d
    
    log_info "Esperando a que todos los servicios est√©n saludables..."
    local max_wait=300  # 5 minutos
    local wait_time=0
    
    while [[ $wait_time -lt $max_wait ]]; do
        local unhealthy=$(docker compose ps --format json | jq -r 'select(.Health != "healthy" and .Health != "") | .Service' | wc -l)
        
        if [[ $unhealthy -eq 0 ]]; then
            log_success "Todos los servicios est√°n saludables"
            break
        fi
        
        log_info "Esperando servicios... ($wait_time/${max_wait}s)"
        sleep 10
        wait_time=$((wait_time + 10))
    done
    
    if [[ $wait_time -ge $max_wait ]]; then
        log_error "Timeout esperando servicios saludables"
        docker compose ps
        exit 1
    fi
}

# Funci√≥n de verificaci√≥n post-despliegue
verify_pipeline() {
    print_section "VERIFICACI√ìN DEL PIPELINE"
    
    log_info "Verificando conectividad de servicios..."
    
    # Verificar ClickHouse
    log_info "Verificando ClickHouse..."
    if docker compose exec clickhouse clickhouse-client --query "SELECT 1" >/dev/null 2>&1; then
        log_success "‚úÖ ClickHouse respondiendo"
    else
        log_error "‚ùå ClickHouse no responde"
        return 1
    fi
    
    # Verificar Kafka
    log_info "Verificando Kafka..."
    if docker compose exec kafka kafka-topics --bootstrap-server kafka:9092 --list >/dev/null 2>&1; then
        log_success "‚úÖ Kafka respondiendo"
    else
        log_error "‚ùå Kafka no responde"
        return 1
    fi
    
    # Verificar Kafka Connect
    log_info "Verificando Kafka Connect..."
    if docker compose exec connect curl -s http://connect:8083/connectors >/dev/null 2>&1; then
        log_success "‚úÖ Kafka Connect respondiendo"
    else
        log_error "‚ùå Kafka Connect no responde"
        return 1
    fi
    
    # Verificar Superset
    log_info "Verificando Superset..."
    if docker compose exec superset curl -s http://superset:8088/health >/dev/null 2>&1; then
        log_success "‚úÖ Superset respondiendo"
    else
        log_warning "‚ö†Ô∏è Superset podr√≠a no estar completamente listo"
    fi
    
    log_success "Verificaci√≥n de servicios completada"
}

# Funci√≥n de configuraci√≥n autom√°tica
auto_configure() {
    print_section "CONFIGURACI√ìN AUTOM√ÅTICA"
    
    log_info "Generando configuraci√≥n de pipeline..."
    docker compose exec pipeline-gen python3 tools/gen_pipeline.py || {
        log_error "Error generando configuraci√≥n de pipeline"
        return 1
    }
    
    log_info "Aplicando conectores Debezium..."
    docker compose exec etl-tools python3 tools/apply_connectors_auto.py || {
        log_error "Error aplicando conectores"
        return 1
    }
    
    log_info "Configurando Superset..."
    docker compose exec etl-tools python3 tools/superset_auto_configurator.py || {
        log_warning "Configuraci√≥n de Superset fall√≥ (podr√≠a necesitar configuraci√≥n manual)"
    }
    
    log_success "Configuraci√≥n autom√°tica completada"
}

# Funci√≥n de reporte final
final_report() {
    print_section "REPORTE FINAL"
    
    echo "üéØ SERVICIOS DISPONIBLES:"
    echo "  üìä ClickHouse:    http://localhost:8123"
    echo "  üîó Kafka Connect: http://localhost:8083"
    echo "  üìà Superset:      http://localhost:8088"
    echo "  üêò Kafka:         localhost:19092"
    
    echo
    echo "üë§ CREDENCIALES:"
    echo "  Superset Admin:   ${SUPERSET_ADMIN:-admin} / ${SUPERSET_PASSWORD:-Admin123!}"
    echo "  ClickHouse ETL:   ${CH_USER:-etl} / ${CH_PASSWORD:-Et1Ingest!}"
    
    echo
    echo "üìã COMANDOS √öTILES:"
    echo "  Ver logs:         docker compose logs -f"
    echo "  Estado servicios: docker compose ps"
    echo "  Ejecutar scripts: docker compose exec etl-tools python3 tools/[script].py"
    echo "  Validar pipeline: docker compose exec etl-tools python3 tools/pipeline_status.py"
    
    echo
    log_success "üéâ ¬°PIPELINE ETL INICIADO CORRECTAMENTE!"
}

# =============================================================================
# EJECUCI√ìN PRINCIPAL
# =============================================================================

print_section "INICIO DEL PIPELINE ETL"
log_info "Configuraci√≥n desde: $(pwd)/.env"
log_info "Proyecto: ${COMPOSE_PROJECT_NAME:-etl_prod}"

# 1. Validar configuraci√≥n
validate_configuration

# Si solo validaci√≥n, terminar aqu√≠
if [[ "$VALIDATE_ONLY" == true ]]; then
    log_success "Validaci√≥n completada. Use --clean para limpiar y desplegar."
    exit 0
fi

# 2. Limpiar si se solicit√≥
if [[ "$CLEAN_MODE" == true ]]; then
    clean_environment
fi

# 3. Desplegar servicios
deploy_pipeline

# 4. Verificar servicios
verify_pipeline

# 5. Configurar autom√°ticamente
auto_configure

# 6. Reporte final
final_report

log_success "üöÄ Pipeline ETL completamente operativo"