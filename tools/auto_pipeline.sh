#!/bin/bash
# Orquestador automÃ¡tico sin dependencias de Docker socket
# Se ejecuta automÃ¡ticamente al iniciar los contenedores

set -e
set -o pipefail

# ConfiguraciÃ³n de logs detallados
LOG_FILE="/app/logs/auto_pipeline_detailed.log"
mkdir -p /app/logs

# FunciÃ³n de logging
log_message() {
    local level=$1
    local message=$2
    local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
    echo "[$timestamp] [$level] $message" | tee -a "$LOG_FILE"
}

# FunciÃ³n para ejecutar comandos con logs (salida visible y persistente)
execute_with_log() {
    local description=$1
    local command=$2
    
    log_message "INFO" "ðŸš§ INICIANDO: $description"
    
    if eval "$command" 2>&1 | tee -a "$LOG_FILE"; then
        log_message "SUCCESS" "âœ… COMPLETADO: $description"
        return 0
    else
        log_message "ERROR" "âŒ FALLÃ“: $description"
        return 1
    fi
}

echo "ðŸš€ INICIANDO PIPELINE ETL AUTOMÃTICO..."
echo "â° $(date)"
log_message "INFO" "ðŸš€ INICIANDO PIPELINE ETL AUTOMÃTICO - $(date)"

# Verificar estado limpio del sistema (solo si ClickHouse estÃ¡ disponible)
log_message "INFO" "ðŸ” FASE 0: VerificaciÃ³n de estado limpio del sistema"
if command -v clickhouse-client &> /dev/null; then
    if python3 tools/verify_clean_state.py 2>&1 | tee -a "$LOG_FILE"; then
        log_message "SUCCESS" "âœ… VerificaciÃ³n de estado limpio completada"
    else
        log_message "WARNING" "âš ï¸  Sistema tiene datos antiguos - se recomienda limpieza"
    fi
else
    log_message "INFO" "â„¹ï¸  VerificaciÃ³n de estado limpio omitida (clickhouse-client no disponible en este contenedor)"
fi

# FunciÃ³n para esperar servicios
wait_for_service() {
    local service_name=$1
    local host=$2
    local port=$3
    local max_attempts=30
    local attempt=1
    
    log_message "INFO" "â³ Esperando $service_name en $host:$port..."
    echo "â³ Esperando $service_name en $host:$port..."
    
    while [ $attempt -le $max_attempts ]; do
        if nc -z $host $port 2>/dev/null; then
            log_message "SUCCESS" "âœ… $service_name estÃ¡ listo despuÃ©s de $attempt intentos"
            echo "âœ… $service_name estÃ¡ listo"
            return 0
        fi
        if [ $((attempt % 5)) -eq 0 ]; then
            log_message "INFO" "   Esperando $service_name... intento $attempt/$max_attempts"
        fi
        echo "   Intento $attempt/$max_attempts..."
        sleep 2
        attempt=$((attempt + 1))
    done
    
    log_message "ERROR" "âŒ $service_name no respondiÃ³ despuÃ©s de $max_attempts intentos"
    echo "âŒ $service_name no respondiÃ³ despuÃ©s de $max_attempts intentos"
    return 1
}

# Esperar servicios crÃ­ticos
log_message "INFO" "ðŸ“‹ FASE 1: VerificaciÃ³n de servicios crÃ­ticos"
wait_for_service "ClickHouse" "clickhouse" "8123" || exit 1
# Validar autenticaciÃ³n HTTP a ClickHouse con las credenciales del entorno
if ! python3 tools/test_clickhouse_auth.py; then
    log_message "ERROR" "âŒ FallÃ³ autenticaciÃ³n HTTP a ClickHouse. Revisa CLICKHOUSE_* o CH_* en .env"
    exit 1
fi
wait_for_service "Kafka Connect" "connect" "8083" || exit 1

# PequeÃ±a pausa adicional para estabilizaciÃ³n
log_message "INFO" "â³ Esperando estabilizaciÃ³n de servicios (15s)..."
echo "â³ Esperando estabilizaciÃ³n de servicios..."
sleep 15
log_message "SUCCESS" "âœ… Servicios estabilizados"

log_message "INFO" "ðŸ“‹ FASE 2: Ingesta automÃ¡tica de datos"
echo "ðŸŽ¯ EJECUTANDO INGESTA AUTOMÃTICA DE DATOS..."

# Ejecutar ingesta multi-database con logs detallados
log_message "INFO" "ðŸ”„ Iniciando ingesta multi-database desde DB_CONNECTIONS..."
log_message "INFO" "   - Parseando configuraciÃ³n desde .env"
log_message "INFO" "   - Procesando todas las conexiones definidas"
log_message "INFO" "   - Chunk size: 50,000 por defecto"

if python3 tools/multi_database_ingest.py 2>&1 | tee -a "$LOG_FILE"; then
    
    # Verificar reporte multi-database
    log_message "INFO" "ðŸ” Verificando datos ingresados..."
    if [ -f "/app/logs/multi_database_ingest_report.json" ]; then
        TOTAL_ROWS=$(python3 -c "
import json
try:
    with open('/app/logs/multi_database_ingest_report.json', 'r') as f:
        report = json.load(f)
    print(report['summary']['total_records_processed'])
except:
    print('0')
" 2>/dev/null || echo "0")
        log_message "SUCCESS" "âœ… Ingesta completada: $TOTAL_ROWS registros totales"
        
        # Verificar datos en ClickHouse
        log_message "INFO" "ðŸ” Verificando tablas y registros en ClickHouse..."
        if command -v clickhouse-client &> /dev/null; then
            echo "ðŸ“Š Tablas creadas en ClickHouse:" | tee -a "$LOG_FILE"
            clickhouse-client --user="${CLICKHOUSE_USER:-default}" --password="${CLICKHOUSE_PASSWORD:-ClickHouse123!}" \
                --query="SELECT database, name, total_rows FROM system.tables WHERE database NOT IN ('system', 'information_schema', 'INFORMATION_SCHEMA') AND name NOT LIKE '.inner%' ORDER BY database, name FORMAT PrettyCompact" \
                2>&1 | tee -a "$LOG_FILE" || true
        fi
    else
        TOTAL_ROWS="0"
        log_message "WARNING" "âš ï¸ Reporte multi-database no encontrado"
    fi
    # No bloquear por 0 filas: algunas tablas pueden no devolver datos en esta fase.
    INGESTION_SUCCESS=true
else
    log_message "ERROR" "âŒ Error en la ingesta multi-database"
    INGESTION_SUCCESS=false
fi

if [ "$INGESTION_SUCCESS" = true ]; then
    log_message "SUCCESS" "âœ… INGESTA DE DATOS COMPLETADA EXITOSAMENTE"
    echo "âœ… INGESTA DE DATOS COMPLETADA EXITOSAMENTE"
    
    # NUEVA FASE: Esperar a que Debezium complete el snapshot inicial
    log_message "INFO" "ðŸ“‹ FASE 2.5: Esperando snapshot inicial de Debezium"
    echo "ðŸ”„ ESPERANDO SNAPSHOT INICIAL DE DEBEZIUM..."
    echo "â„¹ï¸  Esto puede tardar varios minutos dependiendo del tamaÃ±o de las tablas..."
    
    if python3 tools/wait_for_debezium_snapshot.py 2>&1 | tee -a "$LOG_FILE"; then
        log_message "SUCCESS" "âœ… Snapshot de Debezium completado"
        echo "âœ… Snapshot de Debezium completado"
    else
        log_message "WARNING" "âš ï¸ Timeout esperando snapshot (continuarÃ¡ en background)"
        echo "âš ï¸ Timeout esperando snapshot (continuarÃ¡ en background)"
    fi

    # NUEVA FASE: DiagnÃ³stico y auto-reparaciÃ³n CDC (Kafka-ClickHouse)
    log_message "INFO" "ðŸ› ï¸  FASE 2.6: DiagnÃ³stico y ajuste del pipeline CDC"
    echo "ðŸ§ª Ejecutando diagnÃ³stico CDC (ClickHouse-Kafka-MVs)..."
    if python3 tools/diagnose_and_fix_cdc_pipeline.py 2>&1 | tee -a "$LOG_FILE"; then
        log_message "SUCCESS" "âœ… DiagnÃ³stico CDC ejecutado"
    else
        log_message "WARNING" "âš ï¸ DiagnÃ³stico CDC encontrÃ³ problemas (se intentÃ³ auto-reparar)"
    fi
    echo "â³ Esperando 20s para que las MVs reanuden consumo..."
    sleep 20
    
    # VerificaciÃ³n POST-ingesta de ClickHouse
    log_message "INFO" "ðŸ“‹ FASE 2.7: VerificaciÃ³n POST-ingesta de ClickHouse"
    echo "ðŸ” Ejecutando verificaciÃ³n de ClickHouse..."
    if bash tools/verificaciones/clickhouse_verify.sh 2>&1 | tee -a "$LOG_FILE"; then
        log_message "SUCCESS" "âœ… VerificaciÃ³n de ClickHouse completada"
        echo "ðŸ“Š Ver detalles en: logs/clickhouse_verify_latest.log"
    else
        log_message "WARNING" "âš ï¸ VerificaciÃ³n de ClickHouse encontrÃ³ problemas"
    fi
    
    # VerificaciÃ³n de Kafka y Connect
    log_message "INFO" "ðŸ“‹ FASE 2.8: VerificaciÃ³n de Kafka y Connect"
    echo "ðŸ” Ejecutando verificaciÃ³n de Kafka..."
    if bash tools/verificaciones/kafka_verify.sh 2>&1 | tee -a "$LOG_FILE"; then
        log_message "SUCCESS" "âœ… VerificaciÃ³n de Kafka completada"
        echo "ðŸ“Š Ver detalles en: logs/kafka_verify_latest.log"
    else
        log_message "WARNING" "âš ï¸ VerificaciÃ³n de Kafka encontrÃ³ problemas"
    fi
    
    # Configurar Superset datasets automÃ¡ticamente
    log_message "INFO" "ðŸ“‹ FASE 3: ConfiguraciÃ³n automÃ¡tica de Superset"
    echo "ðŸ“Š CONFIGURANDO SUPERSET AUTOMÃTICAMENTE..."
    
    # Esperar que Superset estÃ© listo
    wait_for_service "Superset" "superset" "8088" || exit 1
    
    # Inicializar Superset automÃ¡ticamente
    log_message "INFO" "ðŸ”§ Creando usuario administrador de Superset..."
    echo "ðŸ”§ Inicializando Superset..."
    
    # Crear/resetear usuario admin con contraseÃ±a estandarizada
    ADMIN_PASSWORD="${SUPERSET_PASSWORD:-Admin123!}"
    echo "ðŸ” Configurando admin con contraseÃ±a: ${ADMIN_PASSWORD:0:6}***"
    
    # Intentar crear admin (falla si ya existe, pero no importa)
    docker compose exec -T superset superset fab create-admin \
        --username "${SUPERSET_USERNAME:-admin}" \
        --firstname Admin \
        --lastname User \
        --email admin@example.com \
        --password "$ADMIN_PASSWORD" 2>&1 | tee -a "$LOG_FILE" || \
    log_message "INFO" "Admin ya existe, reseteando contraseÃ±a..."
    
    # Resetear contraseÃ±a para asegurar sincronizaciÃ³n
    execute_with_log "Resetear contraseÃ±a del admin" \
        "docker compose exec -T superset superset fab reset-password --username \"${SUPERSET_USERNAME:-admin}\" --password \"$ADMIN_PASSWORD\""
    
    execute_with_log "Actualizar base de datos de Superset" \
        "docker compose exec -T superset superset db upgrade"
    
    execute_with_log "Inicializar roles y permisos de Superset" \
        "docker compose exec -T superset superset init"
    

    # Configurar ClickHouse en Superset automÃ¡ticamente
    log_message "INFO" "ðŸ”— Configurando conexiÃ³n ClickHouse en Superset..."
    echo "ðŸ“Š Configurando base de datos ClickHouse en Superset..."
    
    if python3 superset_bootstrap/configure_clickhouse_automatic.py 2>&1 | tee -a "$LOG_FILE"; then
        log_message "SUCCESS" "âœ… Superset configurado correctamente con ClickHouse"
        echo "âœ… Superset configurado correctamente con ClickHouse"
        SUPERSET_CONFIG_SUCCESS=true
    else
        log_message "WARNING" "âš ï¸ Superset disponible pero configuraciÃ³n manual requerida"
        echo "âš ï¸  Superset disponible pero configuraciÃ³n manual requerida"
        SUPERSET_CONFIG_SUCCESS=false
    fi

    # Limpieza automÃ¡tica de datasets del esquema base (solo analytics visibles)
    log_message "INFO" "ðŸ§¹ Limpiando datasets del esquema base en Superset..."
    echo "ðŸ§¹ Limpiando datasets del esquema base en Superset..."
    if python3 tools/cleanup_superset_base_datasets.py 2>&1 | tee -a "$LOG_FILE"; then
        log_message "SUCCESS" "âœ… Datasets del esquema base eliminados"
        echo "âœ… Datasets del esquema base eliminados"
    else
        log_message "WARNING" "âš ï¸ Error limpiando datasets del esquema base"
        echo "âš ï¸ Error limpiando datasets del esquema base"
    fi
    
    # Verificar datasets configurados en Superset
    log_message "INFO" "ðŸ“Š Verificando datasets configurados en Superset..."
    echo "ðŸ“Š Datasets configurados en Superset:" | tee -a "$LOG_FILE"
    python3 -c "
import requests
import os
import sys

url = os.getenv('SUPERSET_URL', 'http://superset:8088')
admin = os.getenv('SUPERSET_ADMIN', 'admin')
pwd = os.getenv('SUPERSET_PASSWORD', 'Admin123!')

try:
    # Login
    resp = requests.post(f'{url}/api/v1/security/login', json={'username': admin, 'password': pwd, 'provider': 'db', 'refresh': True}, timeout=10)
    if resp.status_code != 200:
        print(f'âš ï¸  No se pudo autenticar en Superset')
        sys.exit(0)
    
    token = resp.json().get('access_token')
    headers = {'Authorization': f'Bearer {token}'}
    
    # Obtener datasets
    ds_resp = requests.get(f'{url}/api/v1/dataset/', headers=headers, timeout=10)
    if ds_resp.status_code != 200:
        print(f'âš ï¸  Error obteniendo datasets: {ds_resp.status_code}')
        sys.exit(0)
    
    datasets = ds_resp.json().get('result', [])
    print(f'âœ… Total de datasets: {len(datasets)}')
    for ds in datasets[:10]:  # Mostrar primeros 10
        print(f'   - {ds.get(\"schema\", \"\")}.{ds.get(\"table_name\", \"\")}')
    if len(datasets) > 10:
        print(f'   ... y {len(datasets) - 10} mÃ¡s')
except Exception as e:
    print(f'âš ï¸  Error verificando datasets: {e}')
" 2>&1 | tee -a "$LOG_FILE" || true
    
    # VerificaciÃ³n completa de Superset
    log_message "INFO" "ðŸ“‹ FASE 3.9: VerificaciÃ³n completa de Superset"
    echo "ðŸ” Ejecutando verificaciÃ³n completa de Superset..."
    if bash tools/verificaciones/superset_verify.sh 2>&1 | tee -a "$LOG_FILE"; then
        log_message "SUCCESS" "âœ… VerificaciÃ³n de Superset completada"
        echo "ðŸ“Š Ver detalles en: logs/superset_verify_latest.log"
    else
        log_message "WARNING" "âš ï¸ VerificaciÃ³n de Superset encontrÃ³ problemas"
    fi
    
    # ValidaciÃ³n final
    log_message "INFO" "ðŸ“‹ FASE 4: ValidaciÃ³n final del pipeline"
    execute_with_log "ValidaciÃ³n final del pipeline" \
        "python3 tools/validate_final_pipeline.py"
    
    # VerificaciÃ³n de automatizaciÃ³n completa
    log_message "INFO" "ðŸ“‹ FASE 5: VerificaciÃ³n de automatizaciÃ³n completa"
    execute_with_log "VerificaciÃ³n de que todo estÃ¡ automatizado" \
        "python3 tools/verify_automation.py"
    
    # VerificaciÃ³n consolidada de todos los componentes
    log_message "INFO" "ðŸ“‹ FASE 6: VerificaciÃ³n consolidada final"
    echo "ðŸ” Ejecutando verificaciÃ³n consolidada de todos los componentes..."
    if bash tools/run_verifications.sh 2>&1 | tee -a "$LOG_FILE"; then
        log_message "SUCCESS" "âœ… VerificaciÃ³n consolidada completada - Ver logs/verificacion_consolidada_latest.log"
        echo "ðŸ“Š Reporte consolidado: logs/verificacion_consolidada_latest.json"
    else
        log_message "WARNING" "âš ï¸ Algunas verificaciones fallaron - revisar logs/verificacion_consolidada_latest.log"
    fi
    
    log_message "SUCCESS" "ðŸŽ‰ PIPELINE ETL COMPLETADO AUTOMÃTICAMENTE"
    echo "ðŸŽ‰ PIPELINE ETL COMPLETADO AUTOMÃTICAMENTE"
    echo "ðŸ“ˆ Superset disponible en: http://localhost:8088"
    echo "ðŸ‘¤ Usuario: ${SUPERSET_USERNAME:-admin} / ContraseÃ±a: ${SUPERSET_PASSWORD:-Admin123!}"
    
    # Guardar estado de Ã©xito detallado
    cat > /app/logs/auto_pipeline_status.json << EOF
{
  "status": "success",
  "timestamp": "$(date -Iseconds)",
  "message": "Pipeline ETL completado automÃ¡ticamente",
  "details": {
    "ingestion_success": $INGESTION_SUCCESS,
    "superset_config_success": $SUPERSET_CONFIG_SUCCESS,
    "total_rows_ingested": $TOTAL_ROWS,
    "superset_url": "http://localhost:8088",
    "credentials": "${SUPERSET_USERNAME:-admin}/${SUPERSET_PASSWORD:-Admin123!}"
  }
}
EOF
    
else
    log_message "ERROR" "âŒ ERROR EN LA INGESTA DE DATOS"
    echo "âŒ ERROR EN LA INGESTA DE DATOS"
    
    cat > /app/logs/auto_pipeline_status.json << EOF
{
  "status": "error",
  "timestamp": "$(date -Iseconds)",
  "message": "Error en ingesta de datos",
  "details": {
    "ingestion_success": false,
    "error_phase": "data_ingestion"
  }
}
EOF
    exit 1
fi

log_message "SUCCESS" "ðŸ ORQUESTACIÃ“N AUTOMÃTICA FINALIZADA - DuraciÃ³n: $SECONDS segundos"
echo "ðŸ ORQUESTACIÃ“N AUTOMÃTICA FINALIZADA"
echo "ðŸ“„ Logs detallados en: $LOG_FILE"
echo "ðŸ“Š Estado del pipeline en: /app/logs/auto_pipeline_status.json"