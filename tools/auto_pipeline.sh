#!/bin/bash
# Orquestador automÃ¡tico sin dependencias de Docker socket
# Se ejecuta automÃ¡ticamente al iniciar los contenedores

set -e

# ConfiguraciÃ³n de logs detallados
LOG_FILE="/app/logs/auto_pipeline_detailed.log"
mkdir -p /app/logs

# FunciÃ³n de logging
log_message() {
    local level=$1
    local message=$2
    local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
    echo "[$timestamp] [$level] $message" | tee -a "$LOG_FILE"
}

# FunciÃ³n para ejecutar comandos con logs
execute_with_log() {
    local description=$1
    local command=$2
    
    log_message "INFO" "ï¿½ INICIANDO: $description"
    
    if eval "$command" >> "$LOG_FILE" 2>&1; then
        log_message "SUCCESS" "âœ… COMPLETADO: $description"
        return 0
    else
        log_message "ERROR" "âŒ FALLÃ“: $description"
        return 1
    fi
}

echo "ï¿½ðŸš€ INICIANDO PIPELINE ETL AUTOMÃTICO..."
echo "â° $(date)"
log_message "INFO" "ðŸš€ INICIANDO PIPELINE ETL AUTOMÃTICO - $(date)"

# FunciÃ³n para esperar servicios
wait_for_service() {
    local service_name=$1
    local host=$2
    local port=$3
    local max_attempts=30
    local attempt=1
    
    log_message "INFO" "â³ Esperando $service_name en $host:$port..."
    echo "â³ Esperando $service_name en $host:$port..."
    
    while [ $attempt -le $max_attempts ]; do
        if nc -z $host $port 2>/dev/null; then
            log_message "SUCCESS" "âœ… $service_name estÃ¡ listo despuÃ©s de $attempt intentos"
            echo "âœ… $service_name estÃ¡ listo"
            return 0
        fi
        if [ $((attempt % 5)) -eq 0 ]; then
            log_message "INFO" "   Esperando $service_name... intento $attempt/$max_attempts"
        fi
        echo "   Intento $attempt/$max_attempts..."
        sleep 2
        attempt=$((attempt + 1))
    done
    
    log_message "ERROR" "âŒ $service_name no respondiÃ³ despuÃ©s de $max_attempts intentos"
    echo "âŒ $service_name no respondiÃ³ despuÃ©s de $max_attempts intentos"
    return 1
}

# Esperar servicios crÃ­ticos
log_message "INFO" "ðŸ“‹ FASE 1: VerificaciÃ³n de servicios crÃ­ticos"
wait_for_service "ClickHouse" "clickhouse" "8123" || exit 1
wait_for_service "Kafka Connect" "connect" "8083" || exit 1

# PequeÃ±a pausa adicional para estabilizaciÃ³n
log_message "INFO" "â³ Esperando estabilizaciÃ³n de servicios (15s)..."
echo "â³ Esperando estabilizaciÃ³n de servicios..."
sleep 15
log_message "SUCCESS" "âœ… Servicios estabilizados"

log_message "INFO" "ðŸ“‹ FASE 2: Ingesta automÃ¡tica de datos"
echo "ðŸŽ¯ EJECUTANDO INGESTA AUTOMÃTICA DE DATOS..."

# Ejecutar ingesta multi-database con logs detallados
log_message "INFO" "ðŸ”„ Iniciando ingesta multi-database desde DB_CONNECTIONS..."
log_message "INFO" "   - Parseando configuraciÃ³n desde .env"
log_message "INFO" "   - Procesando todas las conexiones definidas"
log_message "INFO" "   - Chunk size: 50,000 por defecto"

if python3 tools/multi_database_ingest.py 2>&1 | tee -a "$LOG_FILE"; then
    
    # Verificar reporte multi-database
    log_message "INFO" "ðŸ” Verificando datos ingresados..."
    if [ -f "/app/logs/multi_database_ingest_report.json" ]; then
        TOTAL_ROWS=$(python3 -c "
import json
try:
    with open('/app/logs/multi_database_ingest_report.json', 'r') as f:
        report = json.load(f)
    print(report['summary']['total_records_processed'])
except:
    print('0')
" 2>/dev/null || echo "0")
        log_message "SUCCESS" "âœ… Ingesta completada: $TOTAL_ROWS registros totales"
    else
        TOTAL_ROWS="0"
        log_message "WARNING" "âš ï¸ Reporte multi-database no encontrado"
    fi
    
    INGESTION_SUCCESS=true
else
    log_message "ERROR" "âŒ Error en la ingesta multi-database"
    INGESTION_SUCCESS=false
fi

if [ "$INGESTION_SUCCESS" = true ]; then
    log_message "SUCCESS" "âœ… INGESTA DE DATOS COMPLETADA EXITOSAMENTE"
    echo "âœ… INGESTA DE DATOS COMPLETADA EXITOSAMENTE"
    
    # Configurar Superset datasets automÃ¡ticamente
    log_message "INFO" "ðŸ“‹ FASE 3: ConfiguraciÃ³n automÃ¡tica de Superset"
    echo "ðŸ“Š CONFIGURANDO SUPERSET AUTOMÃTICAMENTE..."
    
    # Esperar que Superset estÃ© listo
    wait_for_service "Superset" "superset" "8088" || exit 1
    
    # Inicializar Superset automÃ¡ticamente
    log_message "INFO" "ðŸ”§ Creando usuario administrador de Superset..."
    echo "ðŸ”§ Inicializando Superset..."
    
    execute_with_log "Crear usuario admin en Superset" \
        "docker compose exec -T superset superset fab create-admin --username admin --firstname Admin --lastname User --email admin@example.com --password admin"
    
    execute_with_log "Actualizar base de datos de Superset" \
        "docker compose exec -T superset superset db upgrade"
    
    execute_with_log "Inicializar roles y permisos de Superset" \
        "docker compose exec -T superset superset init"
    
    # Configurar ClickHouse en Superset automÃ¡ticamente
    log_message "INFO" "ðŸ”— Configurando conexiÃ³n ClickHouse en Superset..."
    echo "ðŸ“Š Configurando base de datos ClickHouse en Superset..."
    
    if python3 superset_bootstrap/configure_clickhouse_automatic.py 2>&1 | tee -a "$LOG_FILE"; then
        log_message "SUCCESS" "âœ… Superset configurado correctamente con ClickHouse"
        echo "âœ… Superset configurado correctamente con ClickHouse"
        SUPERSET_CONFIG_SUCCESS=true
    else
        log_message "WARNING" "âš ï¸ Superset disponible pero configuraciÃ³n manual requerida"
        echo "âš ï¸  Superset disponible pero configuraciÃ³n manual requerida"
        SUPERSET_CONFIG_SUCCESS=false
    fi
    
    # ValidaciÃ³n final
    log_message "INFO" "ðŸ“‹ FASE 4: ValidaciÃ³n final del pipeline"
    execute_with_log "ValidaciÃ³n final del pipeline" \
        "python3 tools/validate_final_pipeline.py"
    
    # VerificaciÃ³n de automatizaciÃ³n completa
    log_message "INFO" "ðŸ“‹ FASE 5: VerificaciÃ³n de automatizaciÃ³n completa"
    execute_with_log "VerificaciÃ³n de que todo estÃ¡ automatizado" \
        "python3 tools/verify_automation.py"
    
    log_message "SUCCESS" "ðŸŽ‰ PIPELINE ETL COMPLETADO AUTOMÃTICAMENTE"
    echo "ðŸŽ‰ PIPELINE ETL COMPLETADO AUTOMÃTICAMENTE"
    echo "ðŸ“ˆ Superset disponible en: http://localhost:8088"
    echo "ðŸ‘¤ Usuario: admin / ContraseÃ±a: admin"
    
    # Guardar estado de Ã©xito detallado
    cat > /app/logs/auto_pipeline_status.json << EOF
{
  "status": "success",
  "timestamp": "$(date -Iseconds)",
  "message": "Pipeline ETL completado automÃ¡ticamente",
  "details": {
    "ingestion_success": $INGESTION_SUCCESS,
    "superset_config_success": $SUPERSET_CONFIG_SUCCESS,
    "total_rows_ingested": $TOTAL_ROWS,
    "superset_url": "http://localhost:8088",
    "credentials": "admin/admin"
  }
}
EOF
    
else
    log_message "ERROR" "âŒ ERROR EN LA INGESTA DE DATOS"
    echo "âŒ ERROR EN LA INGESTA DE DATOS"
    
    cat > /app/logs/auto_pipeline_status.json << EOF
{
  "status": "error",
  "timestamp": "$(date -Iseconds)",
  "message": "Error en ingesta de datos",
  "details": {
    "ingestion_success": false,
    "error_phase": "data_ingestion"
  }
}
EOF
    exit 1
fi

log_message "SUCCESS" "ðŸ ORQUESTACIÃ“N AUTOMÃTICA FINALIZADA - DuraciÃ³n: $SECONDS segundos"
echo "ðŸ ORQUESTACIÃ“N AUTOMÃTICA FINALIZADA"
echo "ðŸ“„ Logs detallados en: $LOG_FILE"
echo "ðŸ“Š Estado del pipeline en: /app/logs/auto_pipeline_status.json"