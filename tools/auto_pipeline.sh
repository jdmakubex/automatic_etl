#!/bin/bash
# Orquestador autom√°tico sin dependencias de Docker socket
# Se ejecuta autom√°ticamente al iniciar los contenedores

set -e
set -o pipefail

# Configuraci√≥n de logs detallados
LOG_FILE="/app/logs/auto_pipeline_detailed.log"
mkdir -p /app/logs

# Funci√≥n de logging
log_message() {
    local level=$1
    local message=$2
    local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
    echo "[$timestamp] [$level] $message" | tee -a "$LOG_FILE"
}

# Funci√≥n para ejecutar comandos con logs (salida visible y persistente)
execute_with_log() {
    local description=$1
    local command=$2
    
    log_message "INFO" "üöß INICIANDO: $description"
    
    if eval "$command" 2>&1 | tee -a "$LOG_FILE"; then
        log_message "SUCCESS" "‚úÖ COMPLETADO: $description"
        return 0
    else
        log_message "ERROR" "‚ùå FALL√ì: $description"
        return 1
    fi
}

echo "üöÄ INICIANDO PIPELINE ETL AUTOM√ÅTICO..."
echo "‚è∞ $(date)"
log_message "INFO" "üöÄ INICIANDO PIPELINE ETL AUTOM√ÅTICO - $(date)"

# Verificar estado limpio del sistema (solo si ClickHouse est√° disponible)
log_message "INFO" "üîç FASE 0: Verificaci√≥n de estado limpio del sistema"
if command -v clickhouse-client &> /dev/null; then
    if python3 tools/verify_clean_state.py 2>&1 | tee -a "$LOG_FILE"; then
        log_message "SUCCESS" "‚úÖ Verificaci√≥n de estado limpio completada"
    else
        log_message "WARNING" "‚ö†Ô∏è  Sistema tiene datos antiguos - se recomienda limpieza"
    fi
else
    log_message "INFO" "‚ÑπÔ∏è  Verificaci√≥n de estado limpio omitida (clickhouse-client no disponible en este contenedor)"
fi

# Funci√≥n para esperar servicios
wait_for_service() {
    local service_name=$1
    local host=$2
    local port=$3
    local max_attempts=30
    local attempt=1
    
    log_message "INFO" "‚è≥ Esperando $service_name en $host:$port..."
    echo "‚è≥ Esperando $service_name en $host:$port..."
    
    while [ $attempt -le $max_attempts ]; do
        if nc -z $host $port 2>/dev/null; then
            log_message "SUCCESS" "‚úÖ $service_name est√° listo despu√©s de $attempt intentos"
            echo "‚úÖ $service_name est√° listo"
            return 0
        fi
        if [ $((attempt % 5)) -eq 0 ]; then
            log_message "INFO" "   Esperando $service_name... intento $attempt/$max_attempts"
        fi
        echo "   Intento $attempt/$max_attempts..."
        sleep 2
        attempt=$((attempt + 1))
    done
    
    log_message "ERROR" "‚ùå $service_name no respondi√≥ despu√©s de $max_attempts intentos"
    echo "‚ùå $service_name no respondi√≥ despu√©s de $max_attempts intentos"
    return 1
}

# Esperar servicios cr√≠ticos
log_message "INFO" "üìã FASE 1: Verificaci√≥n de servicios cr√≠ticos"
wait_for_service "ClickHouse" "clickhouse" "8123" || exit 1
# Validar autenticaci√≥n HTTP a ClickHouse con las credenciales del entorno
if ! python3 tools/test_clickhouse_auth.py; then
    log_message "ERROR" "‚ùå Fall√≥ autenticaci√≥n HTTP a ClickHouse. Revisa CLICKHOUSE_* o CH_* en .env"
    exit 1
fi
wait_for_service "Kafka Connect" "connect" "8083" || exit 1

# Peque√±a pausa adicional para estabilizaci√≥n
log_message "INFO" "‚è≥ Esperando estabilizaci√≥n de servicios (15s)..."
echo "‚è≥ Esperando estabilizaci√≥n de servicios..."
sleep 15
log_message "SUCCESS" "‚úÖ Servicios estabilizados"

log_message "INFO" "üìã FASE 2: Ingesta autom√°tica de datos"
echo "üéØ EJECUTANDO INGESTA AUTOM√ÅTICA DE DATOS..."

# Ejecutar ingesta multi-database con logs detallados
log_message "INFO" "üîÑ Iniciando ingesta multi-database desde DB_CONNECTIONS..."
log_message "INFO" "   - Parseando configuraci√≥n desde .env"
log_message "INFO" "   - Procesando todas las conexiones definidas"
log_message "INFO" "   - Chunk size: 50,000 por defecto"

if python3 tools/multi_database_ingest.py 2>&1 | tee -a "$LOG_FILE"; then
    
    # Verificar reporte multi-database
    log_message "INFO" "üîç Verificando datos ingresados..."
    if [ -f "/app/logs/multi_database_ingest_report.json" ]; then
        TOTAL_ROWS=$(python3 -c "
import json
try:
    with open('/app/logs/multi_database_ingest_report.json', 'r') as f:
        report = json.load(f)
    print(report['summary']['total_records_processed'])
except:
    print('0')
" 2>/dev/null || echo "0")
        log_message "SUCCESS" "‚úÖ Ingesta completada: $TOTAL_ROWS registros totales"
        
        # Verificar datos en ClickHouse
        log_message "INFO" "üîç Verificando tablas y registros en ClickHouse..."
        if command -v clickhouse-client &> /dev/null; then
            echo "üìä Tablas creadas en ClickHouse:" | tee -a "$LOG_FILE"
            clickhouse-client --user="${CLICKHOUSE_USER:-default}" --password="${CLICKHOUSE_PASSWORD:-ClickHouse123!}" \
                --query="SELECT database, name, total_rows FROM system.tables WHERE database NOT IN ('system', 'information_schema', 'INFORMATION_SCHEMA') AND name NOT LIKE '.inner%' ORDER BY database, name FORMAT PrettyCompact" \
                2>&1 | tee -a "$LOG_FILE" || true
        fi
    else
        TOTAL_ROWS="0"
        log_message "WARNING" "‚ö†Ô∏è Reporte multi-database no encontrado"
    fi
    # No bloquear por 0 filas: algunas tablas pueden no devolver datos en esta fase.
    INGESTION_SUCCESS=true
else
    log_message "ERROR" "‚ùå Error en la ingesta multi-database"
    INGESTION_SUCCESS=false
fi

if [ "$INGESTION_SUCCESS" = true ]; then
    log_message "SUCCESS" "‚úÖ INGESTA DE DATOS COMPLETADA EXITOSAMENTE"
    echo "‚úÖ INGESTA DE DATOS COMPLETADA EXITOSAMENTE"
    
    # NUEVA FASE: Esperar a que Debezium complete el snapshot inicial
    log_message "INFO" "üìã FASE 2.5: Esperando snapshot inicial de Debezium"
    echo "üîÑ ESPERANDO SNAPSHOT INICIAL DE DEBEZIUM..."
    echo "‚ÑπÔ∏è  Esto puede tardar varios minutos dependiendo del tama√±o de las tablas..."
    
    if python3 tools/wait_for_debezium_snapshot.py 2>&1 | tee -a "$LOG_FILE"; then
        log_message "SUCCESS" "‚úÖ Snapshot de Debezium completado"
        echo "‚úÖ Snapshot de Debezium completado"
    else
        log_message "WARNING" "‚ö†Ô∏è Timeout esperando snapshot (continuar√° en background)"
        echo "‚ö†Ô∏è Timeout esperando snapshot (continuar√° en background)"
    fi

    # NUEVA FASE: Diagn√≥stico y auto-reparaci√≥n CDC (Kafka-ClickHouse)
    log_message "INFO" "üõ†Ô∏è  FASE 2.6: Diagn√≥stico y ajuste del pipeline CDC"
    echo "üß™ Ejecutando diagn√≥stico CDC (ClickHouse-Kafka-MVs)..."
    if python3 tools/diagnose_and_fix_cdc_pipeline.py 2>&1 | tee -a "$LOG_FILE"; then
        log_message "SUCCESS" "‚úÖ Diagn√≥stico CDC ejecutado"
    else
        log_message "WARNING" "‚ö†Ô∏è Diagn√≥stico CDC encontr√≥ problemas (se intent√≥ auto-reparar)"
    fi
    echo "‚è≥ Esperando 20s para que las MVs reanuden consumo..."
    sleep 20
    
    # Verificaci√≥n POST-ingesta de ClickHouse
    log_message "INFO" "üìã FASE 2.7: Verificaci√≥n POST-ingesta de ClickHouse"
    echo "üîç Ejecutando verificaci√≥n de ClickHouse..."
    if bash tools/verificaciones/clickhouse_verify.sh 2>&1 | tee -a "$LOG_FILE"; then
        log_message "SUCCESS" "‚úÖ Verificaci√≥n de ClickHouse completada"
        echo "üìä Ver detalles en: logs/clickhouse_verify_latest.log"
    else
        log_message "WARNING" "‚ö†Ô∏è Verificaci√≥n de ClickHouse encontr√≥ problemas"
    fi
    
    # Verificaci√≥n de Kafka y Connect
    log_message "INFO" "üìã FASE 2.8: Verificaci√≥n de Kafka y Connect"
    echo "üîç Ejecutando verificaci√≥n de Kafka..."
    if bash tools/verificaciones/kafka_verify.sh 2>&1 | tee -a "$LOG_FILE"; then
        log_message "SUCCESS" "‚úÖ Verificaci√≥n de Kafka completada"
        echo "üìä Ver detalles en: logs/kafka_verify_latest.log"
    else
        log_message "WARNING" "‚ö†Ô∏è Verificaci√≥n de Kafka encontr√≥ problemas"
    fi
    
    # Configurar Superset datasets autom√°ticamente
    log_message "INFO" "üìã FASE 3: Configuraci√≥n autom√°tica de Superset"
    echo "üìä CONFIGURANDO SUPERSET AUTOM√ÅTICAMENTE..."
    
    # Esperar que Superset est√© listo
    wait_for_service "Superset" "superset" "8088" || exit 1
    
    # Inicializar Superset autom√°ticamente
    log_message "INFO" "üîß Creando usuario administrador de Superset..."
    echo "üîß Inicializando Superset..."
    
    # Crear/resetear usuario admin con contrase√±a estandarizada
    ADMIN_PASSWORD="${SUPERSET_PASSWORD:-Admin123!}"
    echo "üîê Configurando admin con contrase√±a: ${ADMIN_PASSWORD:0:6}***"
    
    # Intentar crear admin (falla si ya existe, pero no importa)
    docker compose exec -T superset superset fab create-admin \
        --username "${SUPERSET_USERNAME:-admin}" \
        --firstname Admin \
        --lastname User \
        --email admin@example.com \
        --password "$ADMIN_PASSWORD" 2>&1 | tee -a "$LOG_FILE" || \
    log_message "INFO" "Admin ya existe, reseteando contrase√±a..."
    
    # Resetear contrase√±a para asegurar sincronizaci√≥n
    execute_with_log "Resetear contrase√±a del admin" \
        "docker compose exec -T superset superset fab reset-password --username \"${SUPERSET_USERNAME:-admin}\" --password \"$ADMIN_PASSWORD\""
    
    execute_with_log "Actualizar base de datos de Superset" \
        "docker compose exec -T superset superset db upgrade"
    
    execute_with_log "Inicializar roles y permisos de Superset" \
        "docker compose exec -T superset superset init"
    

    # Configurar ClickHouse en Superset autom√°ticamente
    log_message "INFO" "üîó Configurando conexi√≥n ClickHouse en Superset..."
    echo "üìä Configurando base de datos ClickHouse en Superset..."
    
    if python3 superset_bootstrap/configure_clickhouse_automatic.py 2>&1 | tee -a "$LOG_FILE"; then
        log_message "SUCCESS" "‚úÖ Superset configurado correctamente con ClickHouse"
        echo "‚úÖ Superset configurado correctamente con ClickHouse"
        SUPERSET_CONFIG_SUCCESS=true
    else
        log_message "WARNING" "‚ö†Ô∏è Superset disponible pero configuraci√≥n manual requerida"
        echo "‚ö†Ô∏è  Superset disponible pero configuraci√≥n manual requerida"
        SUPERSET_CONFIG_SUCCESS=false
    fi

    # Limpieza autom√°tica de datasets del esquema base (solo analytics visibles)
    log_message "INFO" "üßπ Limpiando datasets del esquema base en Superset..."
    echo "üßπ Limpiando datasets del esquema base en Superset..."
    if python3 tools/cleanup_superset_base_datasets.py 2>&1 | tee -a "$LOG_FILE"; then
        log_message "SUCCESS" "‚úÖ Datasets del esquema base eliminados"
        echo "‚úÖ Datasets del esquema base eliminados"
    else
        log_message "WARNING" "‚ö†Ô∏è Error limpiando datasets del esquema base"
        echo "‚ö†Ô∏è Error limpiando datasets del esquema base"
    fi
    
    # Verificar datasets configurados en Superset
    log_message "INFO" "üìä Verificando datasets configurados en Superset..."
    echo "üìä Datasets configurados en Superset:" | tee -a "$LOG_FILE"
    python3 -c "
import requests
import os
import sys

url = os.getenv('SUPERSET_URL', 'http://superset:8088')
admin = os.getenv('SUPERSET_ADMIN', 'admin')
pwd = os.getenv('SUPERSET_PASSWORD', 'Admin123!')

try:
    # Login
    resp = requests.post(f'{url}/api/v1/security/login', json={'username': admin, 'password': pwd, 'provider': 'db', 'refresh': True}, timeout=10)
    if resp.status_code != 200:
        print(f'‚ö†Ô∏è  No se pudo autenticar en Superset')
        sys.exit(0)
    
    token = resp.json().get('access_token')
    headers = {'Authorization': f'Bearer {token}'}
    
    # Obtener datasets
    ds_resp = requests.get(f'{url}/api/v1/dataset/', headers=headers, timeout=10)
    if ds_resp.status_code != 200:
        print(f'‚ö†Ô∏è  Error obteniendo datasets: {ds_resp.status_code}')
        sys.exit(0)
    
    datasets = ds_resp.json().get('result', [])
    print(f'‚úÖ Total de datasets: {len(datasets)}')
    for ds in datasets[:10]:  # Mostrar primeros 10
        print(f'   - {ds.get(\"schema\", \"\")}.{ds.get(\"table_name\", \"\")}')
    if len(datasets) > 10:
        print(f'   ... y {len(datasets) - 10} m√°s')
except Exception as e:
    print(f'‚ö†Ô∏è  Error verificando datasets: {e}')
" 2>&1 | tee -a "$LOG_FILE" || true
    
    # Verificaci√≥n completa de Superset
    log_message "INFO" "üìã FASE 3.9: Verificaci√≥n completa de Superset"
    echo "üîç Ejecutando verificaci√≥n completa de Superset..."
    if bash tools/verificaciones/superset_verify.sh 2>&1 | tee -a "$LOG_FILE"; then
        log_message "SUCCESS" "‚úÖ Verificaci√≥n de Superset completada"
        echo "üìä Ver detalles en: logs/superset_verify_latest.log"
    else
        log_message "WARNING" "‚ö†Ô∏è Verificaci√≥n de Superset encontr√≥ problemas"
    fi
    
    # Validaci√≥n final
    log_message "INFO" "üìã FASE 4: Validaci√≥n final del pipeline"
    execute_with_log "Validaci√≥n final del pipeline" \
        "python3 tools/validate_final_pipeline.py"
    
    # Verificaci√≥n de automatizaci√≥n completa
    log_message "INFO" "üìã FASE 5: Verificaci√≥n de automatizaci√≥n completa"
    execute_with_log "Verificaci√≥n de que todo est√° automatizado" \
        "python3 tools/verify_automation.py"
    
    # Verificaci√≥n consolidada de todos los componentes
    log_message "INFO" "üìã FASE 6: Verificaci√≥n consolidada final"
    echo "üîç Ejecutando verificaci√≥n consolidada de todos los componentes..."
    if bash tools/run_verifications.sh 2>&1 | tee -a "$LOG_FILE"; then
        log_message "SUCCESS" "‚úÖ Verificaci√≥n consolidada completada - Ver logs/verificacion_consolidada_latest.log"
        echo "üìä Reporte consolidado: logs/verificacion_consolidada_latest.json"
    else
        log_message "WARNING" "‚ö†Ô∏è Algunas verificaciones fallaron - revisar logs/verificacion_consolidada_latest.log"
    fi
    
    log_message "SUCCESS" "üéâ PIPELINE ETL COMPLETADO AUTOM√ÅTICAMENTE"
    echo "üéâ PIPELINE ETL COMPLETADO AUTOM√ÅTICAMENTE"
    echo "üìà Superset disponible en: http://localhost:8088"
    echo "üë§ Usuario: ${SUPERSET_USERNAME:-admin} / Contrase√±a: ${SUPERSET_PASSWORD:-Admin123!}"
    
    # Guardar estado de √©xito detallado
    cat > /app/logs/auto_pipeline_status.json << EOF
{
  "status": "success",
  "timestamp": "$(date -Iseconds)",
  "message": "Pipeline ETL completado autom√°ticamente",
  "details": {
    "ingestion_success": $INGESTION_SUCCESS,
    "superset_config_success": $SUPERSET_CONFIG_SUCCESS,
    "total_rows_ingested": $TOTAL_ROWS,
    "superset_url": "http://localhost:8088",
    "credentials": "${SUPERSET_USERNAME:-admin}/${SUPERSET_PASSWORD:-Admin123!}"
  }
}
EOF
    
else
    log_message "ERROR" "‚ùå ERROR EN LA INGESTA DE DATOS"
    echo "‚ùå ERROR EN LA INGESTA DE DATOS"
    
    cat > /app/logs/auto_pipeline_status.json << EOF
{
  "status": "error",
  "timestamp": "$(date -Iseconds)",
  "message": "Error en ingesta de datos",
  "details": {
    "ingestion_success": false,
    "error_phase": "data_ingestion"
  }
}
EOF
    exit 1
fi

log_message "SUCCESS" "üèÅ ORQUESTACI√ìN AUTOM√ÅTICA FINALIZADA - Duraci√≥n: $SECONDS segundos"
echo "üèÅ ORQUESTACI√ìN AUTOM√ÅTICA FINALIZADA"
echo "üìÑ Logs detallados en: $LOG_FILE"
echo "üìä Estado del pipeline en: /app/logs/auto_pipeline_status.json"