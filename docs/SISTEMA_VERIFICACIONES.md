# Sistema de Verificaciones AutomÃ¡ticas - DocumentaciÃ³n Completa

## Ãndice
1. [VisiÃ³n General](#visiÃ³n-general)
2. [Scripts de VerificaciÃ³n](#scripts-de-verificaciÃ³n)
3. [IntegraciÃ³n con el Pipeline](#integraciÃ³n-con-el-pipeline)
4. [Uso Manual](#uso-manual)
5. [Formato de Reportes](#formato-de-reportes)
6. [Troubleshooting](#troubleshooting)

---

## VisiÃ³n General

### Problema que Resuelve
Antes, el usuario tenÃ­a que ejecutar mÃºltiples comandos manualmente para verificar:
- Â¿QuÃ© tablas se crearon en ClickHouse?
- Â¿CuÃ¡ntos registros tiene cada tabla?
- Â¿QuÃ© datasets configurÃ³ Superset?
- Â¿Hay datos de ejecuciones anteriores?

### SoluciÃ³n Implementada
Sistema automatizado de verificaciones que:
- âœ… Se ejecuta automÃ¡ticamente despuÃ©s de cada fase del pipeline
- âœ… Genera logs legibles y archivos JSON para anÃ¡lisis
- âœ… Incluye reintentos con backoff exponencial
- âœ… Consolida resultados de mÃºltiples componentes
- âœ… Persiste resultados con timestamps y symlinks a "latest"

---

## Scripts de VerificaciÃ³n

### 1. `clickhouse_verify.sh`

**UbicaciÃ³n**: `tools/verificaciones/clickhouse_verify.sh`

**QuÃ© verifica**:
1. âœ… Conectividad a ClickHouse
2. ğŸ“Š Bases de datos existentes (lista)
3. ğŸ“‹ Tablas con conteo de registros y tamaÃ±o
4. ğŸ“ˆ EstadÃ­sticas generales (total tablas, registros, tamaÃ±o)
5. ğŸ¯ Verifica que `test_table` existe en `fgeo_analytics`

**Variables de entorno usadas**:
```bash
CLICKHOUSE_DEFAULT_USER=default
CLICKHOUSE_DEFAULT_PASSWORD=ClickHouse123!
CLICKHOUSE_HTTP_HOST=clickhouse
CLICKHOUSE_HTTP_PORT=8123
LOG_DIR=/app/logs
```

**Salida**:
- Log: `logs/clickhouse_verify_TIMESTAMP.log`
- JSON: `logs/clickhouse_verify_TIMESTAMP.json`
- Symlink: `logs/clickhouse_verify_latest.{log,json}`

**Ejemplo de JSON generado**:
```json
{
  "timestamp": "2025-10-22T00:30:15Z",
  "host": "clickhouse:8123",
  "connectivity": {"status": "ok"},
  "databases": [["fgeo_analytics"], ["default"]],
  "tables": [
    ["fgeo_analytics", "test_table", 6, 1024]
  ],
  "summary": {
    "total_tables": 1,
    "total_rows": 6,
    "total_size": "1.00 KiB"
  },
  "expected_tables": {
    "test_table": {"exists": true, "rows": 6}
  },
  "status": "completed"
}
```

---

### 2. `superset_verify.sh`

**UbicaciÃ³n**: `tools/verificaciones/superset_verify.sh`

**QuÃ© verifica**:
1. ğŸ“¡ Disponibilidad del endpoint `/health`
2. ğŸ” AutenticaciÃ³n con admin (obtiene token)
3. ğŸ“Š Bases de datos configuradas (lista con IDs)
4. ğŸ“‹ Datasets configurados (lista con esquema y tabla)
5. ğŸ¯ Verifica que el dataset `test_table` existe

**Variables de entorno usadas**:
```bash
SUPERSET_URL=http://superset:8088
SUPERSET_ADMIN=admin
SUPERSET_PASSWORD=Admin123!
LOG_DIR=/app/logs
```

**Salida**:
- Log: `logs/superset_verify_TIMESTAMP.log`
- JSON: `logs/superset_verify_TIMESTAMP.json`
- Symlink: `logs/superset_verify_latest.{log,json}`

**Ejemplo de JSON generado**:
```json
{
  "timestamp": "2025-10-22T00:30:20Z",
  "url": "http://superset:8088",
  "checks": {
    "availability": {"status": "ok", "code": 200},
    "authentication": {"status": "ok", "user": "admin"},
    "databases": {
      "status": "ok",
      "count": 1,
      "list": [
        {"name": "ClickHouse ETL Database", "id": 1}
      ]
    },
    "datasets": {
      "status": "ok",
      "count": 1,
      "list": [
        {"id": 1, "schema": "fgeo_analytics", "table": "test_table"}
      ]
    },
    "expected_dataset": {"status": "ok", "id": 1}
  },
  "status": "completed"
}
```

---

### 3. `kafka_verify.sh`

**UbicaciÃ³n**: `tools/verificaciones/kafka_verify.sh`

**QuÃ© verifica**:
1. ğŸ“¡ Conectividad a Kafka
2. ğŸ“‹ Topics existentes (excluyendo topics del sistema)
3. ğŸ”Œ Disponibilidad de Kafka Connect
4. ğŸ”— Conectores configurados con sus estados

**Variables de entorno usadas**:
```bash
KAFKA_BOOTSTRAP=kafka:9092
CONNECT_URL=http://connect:8083
LOG_DIR=/app/logs
```

**Salida**:
- Log: `logs/kafka_verify_TIMESTAMP.log`
- JSON: `logs/kafka_verify_TIMESTAMP.json`
- Symlink: `logs/kafka_verify_latest.{log,json}`

**Ejemplo de JSON generado**:
```json
{
  "timestamp": "2025-10-22T00:30:18Z",
  "kafka_bootstrap": "kafka:9092",
  "connect_url": "http://connect:8083",
  "checks": {
    "kafka_connectivity": {"status": "ok"},
    "kafka_topics": {
      "status": "ok",
      "count": 0,
      "topics": []
    },
    "connect_connectivity": {"status": "ok", "code": 200},
    "connect_connectors": {
      "status": "ok",
      "count": 0,
      "connectors": []
    }
  },
  "status": "completed"
}
```

---

### 4. `run_verifications.sh` (Orquestador)

**UbicaciÃ³n**: `tools/run_verifications.sh`

**QuÃ© hace**:
1. ğŸ¯ Ejecuta todos los scripts de verificaciÃ³n en orden
2. ğŸ”„ Maneja reintentos con backoff exponencial
3. ğŸ“Š Consolida resultados en un solo reporte
4. ğŸ’¾ Genera log y JSON consolidados
5. âœ… Retorna cÃ³digo de salida apropiado

**ConfiguraciÃ³n de reintentos**:
```bash
VERIFICATIONS=(
    "clickhouse:$VERIFY_DIR/clickhouse_verify.sh:2:5"
    #            script                          ^  ^
    #                                            |  |
    #                                    max_retries |
    #                                           retry_delay (segundos)
    
    "kafka:$VERIFY_DIR/kafka_verify.sh:1:3"
    "superset:$VERIFY_DIR/superset_verify.sh:3:10"
)
```

**Backoff exponencial**:
- Intento 1: espera `delay` segundos
- Intento 2: espera `delay * 2` segundos
- Intento 3: espera `delay * 4` segundos
- ...

**Salida**:
- Log: `logs/verificacion_consolidada_TIMESTAMP.log`
- JSON: `logs/verificacion_consolidada_TIMESTAMP.json`
- Symlink: `logs/verificacion_consolidada_latest.{log,json}`

**Ejemplo de JSON consolidado**:
```json
{
  "timestamp": "2025-10-22T00:30:25Z",
  "components": {
    "clickhouse": {
      "timestamp": "2025-10-22T00:30:15Z",
      "summary": {"total_tables": 1, "total_rows": 6},
      "status": "completed"
    },
    "kafka": {
      "timestamp": "2025-10-22T00:30:18Z",
      "checks": {...},
      "status": "completed"
    },
    "superset": {
      "timestamp": "2025-10-22T00:30:20Z",
      "checks": {...},
      "status": "completed"
    }
  },
  "summary": {
    "total": 3,
    "success": 3,
    "failed": 0,
    "all_passed": true
  }
}
```

---

## IntegraciÃ³n con el Pipeline

### Modificaciones en `auto_pipeline.sh`

#### FASE 0: VerificaciÃ³n Pre-Ingesta
```bash
log_message "INFO" "ğŸ” FASE 0: VerificaciÃ³n de estado limpio"
if python3 tools/verify_clean_state.py; then
    log_message "SUCCESS" "âœ… Sistema limpio"
else
    log_message "WARNING" "âš ï¸  Datos antiguos detectados"
fi
```

#### FASE 2: POST-Ingesta
```bash
# DespuÃ©s de multi_database_ingest.py
log_message "INFO" "ğŸ” Verificando datos ingresados..."

# Mostrar tablas y conteos
clickhouse-client --query="
    SELECT database, name, total_rows 
    FROM system.tables 
    WHERE ...
    FORMAT PrettyCompact
" | tee -a "$LOG_FILE"
```

#### FASE 3: POST-ConfiguraciÃ³n de Superset
```bash
# DespuÃ©s de configurar datasets
log_message "INFO" "ğŸ“Š Verificando datasets configurados..."
python3 -c "
import requests, os
# Obtener lista de datasets vÃ­a API
# Mostrar primeros 10
" | tee -a "$LOG_FILE"
```

#### FASE 5: VerificaciÃ³n Final Completa
```bash
log_message "INFO" "ğŸ” Ejecutando verificaciÃ³n completa de todos los componentes..."
if bash tools/run_verifications.sh; then
    log_message "SUCCESS" "âœ… Todas las verificaciones pasaron"
else
    log_message "WARNING" "âš ï¸  Algunas verificaciones fallaron"
fi
```

---

## Uso Manual

### Ejecutar VerificaciÃ³n Individual

#### ClickHouse
```bash
# Desde el host
docker compose exec etl-orchestrator bash tools/verificaciones/clickhouse_verify.sh

# Ver resultado
cat logs/clickhouse_verify_latest.log
cat logs/clickhouse_verify_latest.json | jq .
```

#### Superset
```bash
docker compose exec etl-orchestrator bash tools/verificaciones/superset_verify.sh
cat logs/superset_verify_latest.log
```

#### Kafka
```bash
docker compose exec etl-orchestrator bash tools/verificaciones/kafka_verify.sh
cat logs/kafka_verify_latest.log
```

### Ejecutar Todas las Verificaciones
```bash
# Desde el host
docker compose exec etl-orchestrator bash tools/run_verifications.sh

# Ver resultado consolidado
cat logs/verificacion_consolidada_latest.log
cat logs/verificacion_consolidada_latest.json | jq .
```

### Ejecutar con Variables Personalizadas
```bash
docker compose exec \
  -e CLICKHOUSE_DEFAULT_USER=myuser \
  -e CLICKHOUSE_DEFAULT_PASSWORD=mypass \
  etl-orchestrator bash tools/verificaciones/clickhouse_verify.sh
```

---

## Formato de Reportes

### Estructura de Directorios de Logs
```
logs/
â”œâ”€â”€ clickhouse_verify_2025-10-22_00-30-15.log
â”œâ”€â”€ clickhouse_verify_2025-10-22_00-30-15.json
â”œâ”€â”€ clickhouse_verify_latest.log â†’ clickhouse_verify_2025-10-22_00-30-15.log
â”œâ”€â”€ clickhouse_verify_latest.json â†’ clickhouse_verify_2025-10-22_00-30-15.json
â”‚
â”œâ”€â”€ superset_verify_2025-10-22_00-30-20.log
â”œâ”€â”€ superset_verify_2025-10-22_00-30-20.json
â”œâ”€â”€ superset_verify_latest.log
â”œâ”€â”€ superset_verify_latest.json
â”‚
â”œâ”€â”€ kafka_verify_2025-10-22_00-30-18.log
â”œâ”€â”€ kafka_verify_2025-10-22_00-30-18.json
â”œâ”€â”€ kafka_verify_latest.log
â”œâ”€â”€ kafka_verify_latest.json
â”‚
â”œâ”€â”€ verificacion_consolidada_2025-10-22_00-30-25.log
â”œâ”€â”€ verificacion_consolidada_2025-10-22_00-30-25.json
â”œâ”€â”€ verificacion_consolidada_latest.log
â”œâ”€â”€ verificacion_consolidada_latest.json
â”‚
â”œâ”€â”€ auto_pipeline_detailed.log
â”œâ”€â”€ auto_pipeline_status.json
â””â”€â”€ clean_state_verification.json
```

### Convenciones de Nombrado
- **Timestamp**: `YYYY-MM-DD_HH-MM-SS`
- **Formato**: `{componente}_verify_{timestamp}.{log|json}`
- **Symlink latest**: `{componente}_verify_latest.{log|json}`

### Campos Comunes en JSON
Todos los JSONs tienen:
```json
{
  "timestamp": "ISO 8601 format",
  "status": "completed|error|warning",
  ...
}
```

---

## Troubleshooting

### Problema: Script no encuentra comando
**SÃ­ntoma**:
```
âš ï¸  Comando kafka-topics no disponible en este contenedor
```

**SoluciÃ³n**:
- Normal. El script detecta y marca como "skipped"
- Si es crÃ­tico, ejecutar desde contenedor que tenga el comando:
  ```bash
  docker compose exec kafka kafka-topics --bootstrap-server localhost:9092 --list
  ```

### Problema: Error de conexiÃ³n
**SÃ­ntoma**:
```json
{"connectivity": {"status": "error"}}
```

**SoluciÃ³n**:
1. Verificar que el servicio estÃ© corriendo:
   ```bash
   docker compose ps
   ```
2. Verificar credenciales en `.env`
3. Verificar red Docker:
   ```bash
   docker network inspect etl_prod_etl_net
   ```

### Problema: Timeout en autenticaciÃ³n
**SÃ­ntoma**:
```
âŒ No se pudo obtener token tras reintentos
```

**SoluciÃ³n**:
1. Verificar que `superset-init` haya completado:
   ```bash
   docker compose ps superset-init
   ```
2. Resetear contraseÃ±a manualmente:
   ```bash
   docker exec superset superset fab reset-password \
     --username admin --password Admin123!
   ```
3. Verificar variables en `.env`:
   ```bash
   grep SUPERSET .env
   ```

### Problema: Datos antiguos detectados
**SÃ­ntoma**:
```
âš ï¸  Sistema con datos antiguos detectados
```

**SoluciÃ³n**:
```bash
# Limpieza total
./tools/clean_all.sh

# Reiniciar pipeline
docker compose up -d
```

### Problema: VerificaciÃ³n falla despuÃ©s de reintentos
**SÃ­ntoma**:
```
ğŸ’” VerificaciÃ³n de superset FALLÃ“ despuÃ©s de 3 intentos
```

**SoluciÃ³n**:
1. Ver log detallado:
   ```bash
   cat logs/superset_verify_latest.log
   ```
2. Ver JSON para detalles programÃ¡ticos:
   ```bash
   cat logs/superset_verify_latest.json | jq '.checks'
   ```
3. Ejecutar manualmente para debugging:
   ```bash
   docker compose exec etl-orchestrator bash -x tools/verificaciones/superset_verify.sh
   ```

---

## Mejoras Futuras

### Configurabilidad
- [ ] Timeouts configurables vÃ­a env vars
- [ ] Reintentos configurables por componente
- [ ] Umbrales de alerta personalizables

### Notificaciones
- [ ] Enviar email/slack en caso de fallo
- [ ] Webhook para integraciÃ³n con herramientas de monitoreo
- [ ] Dashboard web para visualizar reportes

### MÃ©tricas
- [ ] Exportar mÃ©tricas a Prometheus
- [ ] Historial de verificaciones con tendencias
- [ ] Alertas basadas en patrones (ej: tablas creciendo demasiado rÃ¡pido)

---

## Resumen de Archivos

| Archivo | PropÃ³sito | CuÃ¡ndo se ejecuta |
|---------|-----------|-------------------|
| `clickhouse_verify.sh` | Verifica ClickHouse | POST-ingesta, verificaciÃ³n manual |
| `superset_verify.sh` | Verifica Superset | POST-config, verificaciÃ³n manual |
| `kafka_verify.sh` | Verifica Kafka/Connect | POST-config, verificaciÃ³n manual |
| `run_verifications.sh` | Orquestador | FASE 5 (final), verificaciÃ³n manual |
| `verify_clean_state.py` | Estado limpio | FASE 0 (pre-ingesta) |
| `clean_all.sh` | Limpieza total | Antes de nueva ejecuciÃ³n |

---

## Comandos RÃ¡pidos

```bash
# Ver Ãºltima verificaciÃ³n de ClickHouse
cat logs/clickhouse_verify_latest.log

# Ver Ãºltima verificaciÃ³n consolidada
cat logs/verificacion_consolidada_latest.log

# Ejecutar solo verificaciÃ³n de Superset
docker compose exec etl-orchestrator bash tools/verificaciones/superset_verify.sh

# Ejecutar todas las verificaciones manualmente
docker compose exec etl-orchestrator bash tools/run_verifications.sh

# Ver resumen de todas las verificaciones en JSON
cat logs/verificacion_consolidada_latest.json | jq '.summary'

# Buscar errores en logs
grep -r "ERROR\|âŒ" logs/*.log

# Listar todos los reportes generados hoy
ls -lh logs/*$(date +%Y-%m-%d)*.{log,json}
```
