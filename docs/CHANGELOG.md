# Registro de Cambios - Sistema de Robustez y Automatizaci√≥n

## 2025-10-24

### Validaci√≥n de ingesta ETL y datos en ClickHouse

- Se revisaron los logs de ingesta (`logs/ingest_runner.log`, `logs/ingest_status.json`) y se confirm√≥ √©xito: m√°s de 34,000 filas procesadas y 11 tablas actualizadas.
- Validaci√≥n directa en ClickHouse:
  - `fiscalizacion.src__fiscalizacion__fiscalizacion__bitacora`: 513,344 filas
  - `fiscalizacion.src__fiscalizacion__fiscalizacion__ofeindisdup`: 209,171 filas
  - `fiscalizacion.src__fiscalizacion__fiscalizacion__cieps`: 66 filas
  - `fiscalizacion.src__fiscalizacion__fiscalizacion__formatovic`: 106 filas
  - `fiscalizacion.src__fiscalizacion__fiscalizacion__cieps_formatovic`: 129 filas
  - `fiscalizacion.src__fiscalizacion__fiscalizacion__agrupadoai`: 18 filas
  - `fiscalizacion.src__fiscalizacion__fiscalizacion__altoimpacto`: 44 filas
- No se detectaron errores ni advertencias relevantes en la ingesta.
- Siguiente paso: Validar creaci√≥n de gr√°ficas y queries en Superset UI usando estos datos.

---

## 2025-10-23

### Cambios Implementados

#### 1. Superset init: actualizaci√≥n robusta de conexi√≥n ClickHouse

Ubicaci√≥n: `tools/superset_auto_configurator.py`

- Al actualizar la base de datos ‚ÄúClickHouse ETL Database‚Äù, ahora se intenta primero un PATCH con campos seguros (expose_in_sqllab, allow_ctas, allow_cvas, allow_run_async, allow_dml, extra).
- Si el PATCH no est√° permitido (405), se hace fallback a PUT completo y se registran errores detallados.
- Resiliencia: si la actualizaci√≥n falla con 422, el script detecta la BD oficial existente y contin√∫a con su ID para no bloquear el pipeline.

Resultado: `superset-init` ya no se detiene por 422 y el pipeline avanza a la configuraci√≥n de datasets.

#### 2. Post-config de datasets y preferencias de SQL Lab

Ubicaci√≥n: `superset_bootstrap/run_post_config.sh` y scripts asociados

- Se verific√≥ la creaci√≥n/configuraci√≥n autom√°tica de 19 datasets en 2 esquemas.
- Se aplica Time Grain por defecto = None y m√©trica COUNT(*).
- La activaci√≥n ‚ÄúRun Async‚Äù v√≠a API no se pudo forzar por diferencia de endpoint (404/405); se conf√≠a en GLOBAL_ASYNC_QUERIES y la configuraci√≥n UI local. Pendiente: compatibilidad de endpoint para forzar la preferencia a nivel usuario.

Archivos de reporte generados:
- `logs/dataset_candidates.json`
- `logs/dataset_time_mapping.json`

### Pr√≥ximos Pasos

1. Ajustar el endpoint/API para establecer "Run Async" por defecto a nivel usuario (Superset 3.1).
2. Validar en UI: creaci√≥n de gr√°ficas por admin y ausencia de errores con columnas fecha.

#### 3. Validaci√≥n automatizada de Superset UI

Ubicaci√≥n: `tools/validate_superset_ui.py`

- Script de validaci√≥n automatizada que verifica:
  - Autenticaci√≥n admin funcional
  - Base de datos ClickHouse conectada y configurada
  - 19 datasets creados y accesibles
  - Columnas temporales detectadas en datasets relevantes
  - Permisos de admin para crear charts
  - SQL Lab con async habilitado globalmente

Resultado: ‚úÖ Todas las validaciones automatizadas pasaron.

**Estado del sistema**: Listo para validaci√≥n manual en UI.

Documentaci√≥n creada:
- `docs/VALIDATION_CHECKLIST.md`: Checklist completo de validaci√≥n manual con pasos detallados para verificar creaci√≥n de charts, SQL Lab async, y manejo de columnas fecha.

Reporte generado:
- `logs/superset_ui_validation.json`: Resultados completos de validaci√≥n automatizada.

### Pendientes

1. **Validaci√≥n Manual UI** (15-20 min):
   - Crear charts con columnas de fecha
   - Verificar SQL Lab ejecuta en modo async
   - Confirmar ausencia de errores GROUP BY

2. **Ajuste opcional**: Forzar "Run Async" por defecto a nivel usuario v√≠a API (el endpoint /api/v1/me/ retorna 401; la funcionalidad async est√° disponible pero el toggle no se marca autom√°ticamente).

## 2025-10-22

### Cambios Implementados

#### 1. Robustez de Autenticaci√≥n (configure_datasets.py)

**Ubicaci√≥n**: `superset_bootstrap/configure_datasets.py`

**Cambios realizados**:

- Superset datasets bootstrap now reliably runs via corrected docker-compose command (array form and multi-line bash script).
- Automatic dataset column configuration: mark DateTime/Timestamp columns as temporal (is_dttm=True) to avoid GROUP BY errors.
- For existing datasets (422 on create), we now look them up and apply the same configuration.
- Default Explore Time Grain is set to None by writing default_form_data.time_grain_sqla = null to dataset.extra.

#### 2. Dependencias en Docker Compose

**Ubicaci√≥n**: `docker-compose.yml`

**Cambio**:

- The /api/v1/database/{id}/refresh endpoint returns 404 on current Superset build; behavior is tolerated and does not block table listing.
- Temporary debug logs were added to verify the execution flow; they will be removed after validation.


## Fecha: 2025-10-22

### Problema Principal Identificado
El usuario report√≥ que:
1. El pipeline se "atora" en obtenci√≥n de tokens (401 Not authorized)
2. Hay verificaciones manuales que deber√≠an ser autom√°ticas
3. Los datos de ejecuciones anteriores no se limpiaban correctamente
4. Falta trazabilidad de qu√© est√° pasando en cada momento

### Cambios Implementados

#### 1. Robustez de Autenticaci√≥n (configure_datasets.py)

**Ubicaci√≥n**: `superset_bootstrap/configure_datasets.py`

**Cambios realizados**:

```python
# AGREGADO: Espera activa para confirmar que Superset est√° completamente inicializado
def wait_for_superset(url, timeout=300):
    """Esperar a que Superset est√© disponible y completamente inicializado"""
    # Antes: solo verificaba /health
    # Ahora: verifica /health + espera adicional de 10s para inicializaci√≥n completa
    
# AGREGADO: Nueva funci√≥n para esperar al admin
def wait_for_admin_ready(url, username, max_wait=180):
    """Esperar a que el admin user est√© realmente creado y disponible.
    
    Intenta login peri√≥dicamente hasta que funcione.
    - Reintenta cada 3s
    - Log de progreso cada 5 intentos
    - Prueba contrase√±as alternativas si encuentra 401
    """
    # Esta funci√≥n asegura que superset-init haya terminado
    # antes de que superset-datasets intente autenticarse

# MEJORADO: Backoff exponencial en get_auth_token
def get_auth_token(..., initial_backoff=3, max_backoff=30):
    """Obtener token con reintentos inteligentes
    
    Cambios:
    - Backoff exponencial: 3s ‚Üí 4.5s ‚Üí 6.75s ‚Üí 10s ‚Üí 15s ‚Üí 22.5s ‚Üí 30s
    - Log de progreso cada 5 intentos
    - Prueba m√∫ltiples contrase√±as autom√°ticamente
    - Mensajes de error m√°s descriptivos
    """

# MEJORADO: authed_request ya exist√≠a pero se robustece
# Ahora maneja mejor los 401 y actualiza el token_ref globalmente
```

**Raz√≥n del cambio**: 
- El servicio `superset-datasets` se ejecutaba antes de que el admin existiera
- Los reintentos constantes saturaban el servidor
- No hab√≠a visibilidad de qu√© estaba fallando

---

#### 2. Dependencias en Docker Compose

**Ubicaci√≥n**: `docker-compose.yml`

**Cambio**:
```yaml
superset-datasets:
  depends_on:
    superset:
      condition: service_healthy
    superset-init:
      condition: service_completed_successfully  # ‚¨ÖÔ∏è NUEVO
```

**Raz√≥n**: 
- Antes: `superset-datasets` iniciaba apenas Superset estaba "healthy"
- Ahora: espera a que `superset-init` termine de crear el admin
- Elimina race condition entre creaci√≥n de admin y configuraci√≥n de datasets

---

#### 3. Estandarizaci√≥n de Contrase√±as

**Ubicaci√≥n**: `tools/auto_pipeline.sh`

**Antes**:
```bash
execute_with_log "Crear usuario admin en Superset" \
    "docker compose exec -T superset superset fab create-admin ... --password admin"
```

**Ahora**:
```bash
# Usar variable de entorno estandarizada
ADMIN_PASSWORD="${SUPERSET_PASSWORD:-Admin123!}"

# Crear admin
docker compose exec -T superset superset fab create-admin \
    --password "$ADMIN_PASSWORD"

# NUEVO: Siempre resetear para sincronizar
execute_with_log "Resetear contrase√±a del admin" \
    "docker compose exec -T superset superset fab reset-password \
        --username admin --password \"$ADMIN_PASSWORD\""
```

**Raz√≥n**:
- Antes: admin se creaba con "admin", pero otros servicios esperaban "Admin123!"
- Desincronizaci√≥n causaba 401s persistentes
- Ahora: contrase√±a consistente en todos los servicios desde el inicio

---

#### 4. Sistema de Limpieza Total

**Ubicaci√≥n**: `tools/clean_all.sh` (NUEVO)

**Prop√≥sito**: Script unificado para limpiar TODO el sistema

**Funcionalidad**:
```bash
#!/bin/bash
# Detener servicios
docker compose down

# Eliminar vol√∫menes (ClickHouse, Kafka, Superset)
docker compose down -v
docker volume prune -f

# Eliminar redes hu√©rfanas
docker network prune -f

# Limpiar logs y archivos generados
rm -rf logs/*.json logs/*.log
rm -rf generated/*/schemas/*.json

# Mostrar resumen del estado final
```

**Raz√≥n**:
- Usuario report√≥ confusi√≥n por datos antiguos
- Antes: m√∫ltiples comandos manuales necesarios
- Ahora: un solo comando limpia TODO

---

#### 5. Verificaci√≥n Autom√°tica de Estado Limpio

**Ubicaci√≥n**: `tools/verify_clean_state.py` (NUEVO)

**Prop√≥sito**: Detectar autom√°ticamente datos de ejecuciones anteriores

**Funcionalidad**:
```python
def check_clickhouse_databases():
    """Verifica que solo existan las bases esperadas"""
    # Esperadas: fgeo_analytics, default
    # Cualquier otra ‚Üí ALERTA

def check_clickhouse_tables():
    """Verifica que solo exista test_table"""
    # Esperada: fgeo_analytics.test_table
    # Cualquier otra ‚Üí ALERTA

def check_kafka_topics():
    """Verifica que solo existan topics del sistema"""
    # Esperados: connect_configs, connect_offsets, connect_statuses
    # Cualquier otro ‚Üí ALERTA

def check_superset_datasets():
    """Verifica que solo exista test_table en datasets"""
    # Esperado: fgeo_analytics.test_table
    # Cualquier otro ‚Üí ALERTA
```

**Salida**: Genera `logs/clean_state_verification.json` con:
```json
{
  "status": "clean|dirty",
  "timestamp": "...",
  "results": {
    "clickhouse_databases": {"status": "clean", "databases": [...]},
    "clickhouse_tables": {"status": "clean", "tables": [...]},
    ...
  }
}
```

**Integraci√≥n**: Se ejecuta autom√°ticamente en **FASE 0** del pipeline

**Raz√≥n**:
- Antes: verificaci√≥n manual con m√∫ltiples comandos
- Usuario perd√≠a tiempo debuggeando datos antiguos
- Ahora: detecci√≥n autom√°tica con reporte persistente

---

#### 6. Verificaciones POST-Proceso Integradas

**Ubicaci√≥n**: `tools/auto_pipeline.sh`

**FASE 0 (NUEVA)**:
```bash
log_message "INFO" "üîç FASE 0: Verificaci√≥n de estado limpio del sistema"
if python3 tools/verify_clean_state.py; then
    log_message "SUCCESS" "‚úÖ Sistema limpio"
else
    log_message "WARNING" "‚ö†Ô∏è  Datos antiguos detectados"
fi
```

**FASE 2 - POST-Ingesta (MEJORADO)**:
```bash
# Antes: solo mostraba total de registros
# Ahora: tambi√©n lista todas las tablas con conteos
if command -v clickhouse-client &> /dev/null; then
    echo "üìä Tablas creadas en ClickHouse:"
    clickhouse-client --query="
        SELECT database, name, total_rows 
        FROM system.tables 
        WHERE ...
        FORMAT PrettyCompact
    " | tee -a "$LOG_FILE"
fi
```

**FASE 3 - POST-Configuraci√≥n de Superset (NUEVO)**:
```bash
log_message "INFO" "üìä Verificando datasets configurados en Superset..."
python3 -c "
import requests, os
# Login a Superset
# Obtener lista de datasets
# Mostrar primeros 10
" | tee -a "$LOG_FILE"
```

**Raz√≥n**:
- Antes: usuario ejecutaba comandos manuales para ver estado
- No hab√≠a trazabilidad de qu√© se cre√≥ en cada fase
- Ahora: verificaci√≥n autom√°tica con log persistente

---

#### 7. Variables de Entorno Unificadas

**Ubicaci√≥n**: `docker-compose.yml`, `tools/auto_pipeline.sh`

**Estandarizaci√≥n**:
```yaml
# Todos los servicios ahora usan:
- SUPERSET_ADMIN=${SUPERSET_ADMIN:-admin}
- SUPERSET_PASSWORD=${SUPERSET_PASSWORD:-Admin123!}
- SUPERSET_URL=http://superset:8088
```

**En scripts**:
```bash
ADMIN_PASSWORD="${SUPERSET_PASSWORD:-Admin123!}"
echo "üë§ Usuario: ${SUPERSET_USERNAME:-admin} / Contrase√±a: $ADMIN_PASSWORD"
```

**Raz√≥n**:
- Antes: valores hardcodeados en m√∫ltiples lugares
- Inconsistencias causaban 401s
- Ahora: una sola fuente de verdad (.env)

---

### Documentaci√≥n Creada

#### docs/TOKEN_ROBUSTNESS.md
**Contenido**:
- Explicaci√≥n detallada de cada mejora de autenticaci√≥n
- Diagrama de flujo completo del proceso
- Comandos de troubleshooting
- Variables de entorno
- Estrategias de rollback

#### docs/AUTOMATED_VERIFICATIONS.md
**Contenido**:
- Descripci√≥n de cada script de verificaci√≥n
- Flujo automatizado completo (FASE 0-5)
- Reportes generados y su ubicaci√≥n
- Comparaci√≥n antes/despu√©s
- Ejemplos de uso

---

#### 4. Automatizaci√≥n post-ingesta: filtrado y permisos en Superset

Ubicaci√≥n: `tools/superset_post_configurator.py`

- Script que, tras la ingesta ETL, filtra los esquemas/tablas visibles en Superset para mostrar solo los modelos declarados en el pipeline/config.
- Ajusta roles y permisos para el usuario admin y roles est√°ndar, asegurando acceso total y posibilidad de crear charts.
- Corrige la metadata de los datasets (time column, m√©tricas, acceso).
- El flujo es replicable para cualquier base de datos declarada en el pipeline.

---

### Pr√≥ximos Cambios Necesarios

Seg√∫n feedback del usuario, a√∫n faltan:

1. **Scripts de Verificaci√≥n Internos en Contenedores**
   - Convertir comandos manuales en scripts ejecutables
   - Ejemplo: `verificar_clickhouse.sh`, `verificar_superset.sh`
   - Que se ejecuten autom√°ticamente post-proceso

2. **Persistencia de Resultados de Verificaci√≥n**
   - Todos los resultados deben guardarse en `logs/`
   - Formato JSON para an√°lisis program√°tico

3. **Reintentos y Esperas Configurables**
   - Actualmente algunos timeouts son fijos
   - Deber√≠an ser configurables v√≠a env vars

4. **Alertas Claras de Fallos**
   - Mensajes m√°s descriptivos cuando algo falla
   - Sugerencias de qu√© revisar/hacer

---

### Archivos Modificados

```
Modificados:
- superset_bootstrap/configure_datasets.py
- docker-compose.yml
- tools/auto_pipeline.sh

Creados:
- tools/clean_all.sh
- tools/verify_clean_state.py
- docs/TOKEN_ROBUSTNESS.md
- docs/AUTOMATED_VERIFICATIONS.md
- docs/CHANGELOG.md (este archivo)

Pendientes de crear:
- tools/verificaciones/clickhouse_verify.sh
- tools/verificaciones/superset_verify.sh
- tools/verificaciones/kafka_verify.sh
- tools/orchestration_helper.sh (wrapper para ejecutar verificaciones)
```

---

### Contexto para Modelos Futuros

**Si retomas este proyecto**, ten en cuenta:

1. **Problema de Autenticaci√≥n**: 
   - Era causado por race condition entre superset-init y superset-datasets
   - Solucionado con depends_on + wait_for_admin_ready + password reset

2. **Limpieza de Datos**:
   - Usuario quiere estado LIMPIO sin datos antiguos
   - clean_all.sh elimina TODO
   - verify_clean_state.py detecta datos antiguos autom√°ticamente

3. **Filosof√≠a de Dise√±o**:
   - TODO debe ser autom√°tico
   - TODO debe loggearse
   - TODO debe ser verificable
   - NO comandos manuales del usuario

4. **Siguiente Fase**:
   - Crear scripts de verificaci√≥n por componente
   - Persistir todos los resultados en logs/
   - Hacer reintentos/timeouts configurables
   - Mejorar mensajes de error con sugerencias

---

### Testing Realizado

- ‚úÖ Limpieza total verificada (vol√∫menes, redes, logs eliminados)
- ‚è≥ Pipeline limpio con mejoras a√∫n no ejecutado (pendiente de aprobaci√≥n del usuario)
- ‚úÖ Scripts de verificaci√≥n creados y documentados
- ‚úÖ Documentaci√≥n completa generada

---

### Notas T√©cnicas

**Backoff Exponencial**:
```
Intento 1: 3s
Intento 2: 4.5s (3 * 1.5)
Intento 3: 6.75s (4.5 * 1.5)
Intento 4: 10.125s (6.75 * 1.5)
Intento 5: 15.1875s (10.125 * 1.5)
Intento 6: 22.78s (15.1875 * 1.5)
Intento 7+: 30s (l√≠mite m√°ximo)
```

**Contrase√±as Intentadas** (en orden):
1. Contrase√±a proporcionada al script
2. Variable SUPERSET_PASSWORD del entorno
3. "Admin123!" (est√°ndar actual)
4. "admin" (legacy, por compatibilidad)

**Orden de Ejecuci√≥n de Servicios**:
```
1. clickhouse (healthy)
2. kafka (healthy)
3. connect (healthy)
4. superset (healthy)
5. superset-venv-setup (completed)
6. etl-orchestrator (FASE 0-2: ingesta)
7. superset-init (completed) ‚Üí crea admin
8. superset-datasets (completed) ‚Üí configura datasets
```

---

### Estado y checklist de depuraci√≥n Superset UI (2025-10-24)

- Validaci√≥n automatizada: admin puede autenticarse, ver 19 datasets y acceder al formulario de creaci√≥n de charts.
- Configuraci√≥n async global habilitada y base ClickHouse ETL correctamente registrada.
- Problemas detectados:
  - Aparecen esquemas/tablas no deseados en la UI (m√°s all√° de los declarados en el JSON/env).
  - √çconos de advertencia en las tablas (posibles incidencias de metadata, time column, permisos o acceso).
  - El usuario admin est√° limitado para crear charts libremente.
- No hay errores cr√≠ticos en los logs de Superset, solo advertencias menores de configuraci√≥n.

Checklist de depuraci√≥n:
1. Revisar y ajustar permisos/roles en Superset para admin y otros usuarios.
2. Validar que los datasets expuestos en Superset correspondan solo a los modelos/tablas deseados.
3. Revisar la metadata de los datasets: columnas clave, time column, m√©tricas y acceso.
4. Analizar los √≠conos de advertencia en la UI y buscar detalles en los logs.
5. Documentar cualquier cambio y resultado en este CHANGELOG.

---
